"""
Script de prÃ©processing du dataset RetailRocket
Transforme les donnÃ©es brutes en format exploitable pour le dashboard
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime

# Chemins
PROJECT_ROOT = Path(__file__).parent.parent
DATA_RAW_DIR = PROJECT_ROOT / "data" / "raw"
DATA_CLEAN_DIR = PROJECT_ROOT / "data" / "clean"


def load_events():
    """Charger et prÃ©processer le fichier events.csv"""
    print("\nğŸ“¥ Chargement de events.csv...")
    
    events_file = DATA_RAW_DIR / "events.csv"
    if not events_file.exists():
        print(f"âŒ Fichier non trouvÃ©: {events_file}")
        return None
    
    # Charger les donnÃ©es
    df = pd.read_csv(events_file)
    print(f"  âœ“ {len(df):,} Ã©vÃ©nements chargÃ©s")
    
    # Afficher les premiÃ¨res lignes
    print(f"\nğŸ“‹ AperÃ§u des colonnes: {list(df.columns)}")
    print(f"ğŸ“Š Types d'Ã©vÃ©nements: {df['event'].unique().tolist() if 'event' in df.columns else 'N/A'}")
    
    # Convertir timestamp en datetime
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['date'] = df['timestamp'].dt.date
        df['hour'] = df['timestamp'].dt.hour
        print(f"  âœ“ Timestamps convertis")
        print(f"  ğŸ“… PÃ©riode: {df['timestamp'].min()} Ã  {df['timestamp'].max()}")
    
    return df


def load_item_properties():
    """Charger et fusionner les fichiers de propriÃ©tÃ©s des items"""
    print("\nğŸ“¥ Chargement des propriÃ©tÃ©s des items...")
    
    part1_file = DATA_RAW_DIR / "item_properties_part1.csv"
    part2_file = DATA_RAW_DIR / "item_properties_part2.csv"
    
    dfs = []
    
    if part1_file.exists():
        df1 = pd.read_csv(part1_file)
        dfs.append(df1)
        print(f"  âœ“ Part 1: {len(df1):,} lignes")
    
    if part2_file.exists():
        df2 = pd.read_csv(part2_file)
        dfs.append(df2)
        print(f"  âœ“ Part 2: {len(df2):,} lignes")
    
    if not dfs:
        print("  âŒ Aucun fichier de propriÃ©tÃ©s trouvÃ©")
        return None
    
    # Fusionner les parties
    df = pd.concat(dfs, ignore_index=True)
    print(f"  âœ“ Total: {len(df):,} propriÃ©tÃ©s")
    print(f"  ğŸ“‹ Colonnes: {list(df.columns)}")
    
    return df


def load_category_tree():
    """Charger l'arborescence des catÃ©gories"""
    print("\nğŸ“¥ Chargement de category_tree.csv...")
    
    category_file = DATA_RAW_DIR / "category_tree.csv"
    if not category_file.exists():
        print(f"  âŒ Fichier non trouvÃ©")
        return None
    
    df = pd.read_csv(category_file)
    print(f"  âœ“ {len(df):,} catÃ©gories chargÃ©es")
    print(f"  ğŸ“‹ Colonnes: {list(df.columns)}")
    
    return df


def analyze_events(df_events):
    """Analyser les Ã©vÃ©nements"""
    print("\nğŸ“Š ANALYSE DES Ã‰VÃ‰NEMENTS")
    print("=" * 60)
    
    if df_events is None or df_events.empty:
        print("  âŒ Pas de donnÃ©es Ã  analyser")
        return
    
    # Statistiques par type d'Ã©vÃ©nement
    if 'event' in df_events.columns:
        print("\nğŸ“ˆ Distribution des Ã©vÃ©nements:")
        event_counts = df_events['event'].value_counts()
        for event_type, count in event_counts.items():
            percentage = (count / len(df_events)) * 100
            print(f"  â€¢ {event_type}: {count:,} ({percentage:.1f}%)")
    
    # Statistiques utilisateurs
    if 'visitorid' in df_events.columns:
        n_users = df_events['visitorid'].nunique()
        print(f"\nğŸ‘¥ Utilisateurs uniques: {n_users:,}")
        
        # Ã‰vÃ©nements par utilisateur
        events_per_user = df_events.groupby('visitorid').size()
        print(f"  â€¢ Moyenne: {events_per_user.mean():.1f} Ã©vÃ©nements/utilisateur")
        print(f"  â€¢ MÃ©diane: {events_per_user.median():.0f} Ã©vÃ©nements/utilisateur")
    
    # Statistiques produits
    if 'itemid' in df_events.columns:
        n_items = df_events['itemid'].nunique()
        print(f"\nğŸ“¦ Produits uniques: {n_items:,}")
        
        # Top produits
        top_items = df_events['itemid'].value_counts().head(10)
        print(f"\nğŸ† Top 10 produits les plus consultÃ©s:")
        for rank, (item_id, count) in enumerate(top_items.items(), 1):
            print(f"  {rank}. Item {item_id}: {count:,} vues")
    
    # Statistiques temporelles
    if 'date' in df_events.columns:
        print(f"\nğŸ“… PÃ©riode couverte: {df_events['date'].min()} Ã  {df_events['date'].max()}")
        n_days = (df_events['date'].max() - df_events['date'].min()).days
        print(f"  â€¢ DurÃ©e: {n_days} jours")
        print(f"  â€¢ Ã‰vÃ©nements par jour: {len(df_events) / n_days:,.0f}")


def create_users_table(df_events):
    """CrÃ©er une table utilisateurs Ã  partir des Ã©vÃ©nements"""
    print("\nğŸ”¨ CrÃ©ation de la table users...")
    
    if df_events is None or 'visitorid' not in df_events.columns:
        print("  âŒ DonnÃ©es insuffisantes")
        return None
    
    users = df_events.groupby('visitorid').agg({
        'timestamp': ['min', 'max', 'count']
    }).reset_index()
    
    users.columns = ['user_id', 'first_visit', 'last_visit', 'total_events']
    
    # Ajouter des segments basiques
    users['segment'] = pd.cut(
        users['total_events'],
        bins=[0, 5, 20, 100, float('inf')],
        labels=['New', 'Occasional', 'Regular', 'Premium']
    )
    
    print(f"  âœ“ {len(users):,} utilisateurs crÃ©Ã©s")
    return users


def create_products_table(df_events, df_properties):
    """CrÃ©er une table produits"""
    print("\nğŸ”¨ CrÃ©ation de la table products...")
    
    if df_events is None or 'itemid' not in df_events.columns:
        print("  âŒ DonnÃ©es insuffisantes")
        return None
    
    # Statistiques de base par produit
    products = df_events.groupby('itemid').agg({
        'visitorid': 'count',
        'event': lambda x: (x == 'transaction').sum() if 'transaction' in x.values else 0
    }).reset_index()
    
    products.columns = ['product_id', 'view_count', 'purchase_count']
    
    # Ajouter les propriÃ©tÃ©s si disponibles
    if df_properties is not None and 'itemid' in df_properties.columns:
        # Pivot des propriÃ©tÃ©s (simplification)
        props_pivot = df_properties.pivot_table(
            index='itemid',
            columns='property',
            values='value',
            aggfunc='first'
        ).reset_index()
        
        products = products.merge(props_pivot, left_on='product_id', right_on='itemid', how='left')
    
    print(f"  âœ“ {len(products):,} produits crÃ©Ã©s")
    return products


def create_sessions_table(df_events):
    """CrÃ©er une table de sessions"""
    print("\nğŸ”¨ CrÃ©ation de la table sessions...")
    
    if df_events is None:
        print("  âŒ DonnÃ©es insuffisantes")
        return None
    
    # Grouper par utilisateur et date pour crÃ©er des sessions
    sessions = df_events.groupby(['visitorid', 'date']).agg({
        'timestamp': ['min', 'max', 'count'],
        'itemid': 'nunique'
    }).reset_index()
    
    sessions.columns = ['user_id', 'session_date', 'session_start', 'session_end', 'events_count', 'unique_items']
    
    # Ajouter un ID de session
    sessions['session_id'] = range(1, len(sessions) + 1)
    
    print(f"  âœ“ {len(sessions):,} sessions crÃ©Ã©es")
    return sessions


def create_transactions_table(df_events):
    """CrÃ©er une table de transactions"""
    print("\nğŸ”¨ CrÃ©ation de la table transactions...")
    
    if df_events is None or 'event' not in df_events.columns:
        print("  âŒ DonnÃ©es insuffisantes")
        return None
    
    # Filtrer les Ã©vÃ©nements de type 'transaction'
    transactions = df_events[df_events['event'] == 'transaction'].copy()
    
    if transactions.empty:
        print("  âš ï¸  Aucune transaction trouvÃ©e dans les donnÃ©es")
        return None
    
    transactions['transaction_id'] = range(1, len(transactions) + 1)
    transactions = transactions.rename(columns={
        'visitorid': 'user_id',
        'itemid': 'product_id',
        'timestamp': 'transaction_date'
    })
    
    # GÃ©nÃ©rer des montants fictifs (le dataset n'a pas de prix)
    np.random.seed(42)
    transactions['amount'] = np.random.uniform(10, 500, len(transactions)).round(2)
    
    print(f"  âœ“ {len(transactions):,} transactions crÃ©Ã©es")
    print(f"  ğŸ’° CA total (simulÃ©): {transactions['amount'].sum():,.2f}â‚¬")
    
    return transactions


def save_cleaned_data(users, products, sessions, transactions):
    """Sauvegarder les donnÃ©es nettoyÃ©es"""
    print("\nğŸ’¾ Sauvegarde des donnÃ©es nettoyÃ©es...")
    
    DATA_CLEAN_DIR.mkdir(parents=True, exist_ok=True)
    
    datasets = {
        'users': users,
        'products': products,
        'sessions': sessions,
        'transactions': transactions
    }
    
    for name, df in datasets.items():
        if df is not None:
            filepath = DATA_CLEAN_DIR / f"{name}.csv"
            df.to_csv(filepath, index=False)
            print(f"  âœ“ {name}.csv ({len(df):,} lignes)")


def main():
    """Fonction principale"""
    print("=" * 60)
    print("  PREPROCESSING DATASET RETAILROCKET")
    print("=" * 60)
    
    # Charger les donnÃ©es brutes
    df_events = load_events()
    df_properties = load_item_properties()
    df_categories = load_category_tree()
    
    if df_events is None:
        print("\nâŒ Impossible de continuer sans le fichier events.csv")
        return 1
    
    # Analyser les donnÃ©es
    analyze_events(df_events)
    
    # CrÃ©er les tables nettoyÃ©es
    users = create_users_table(df_events)
    products = create_products_table(df_events, df_properties)
    sessions = create_sessions_table(df_events)
    transactions = create_transactions_table(df_events)
    
    # Sauvegarder
    save_cleaned_data(users, products, sessions, transactions)
    
    print("\n" + "=" * 60)
    print("âœ¨ PREPROCESSING TERMINÃ‰ AVEC SUCCÃˆS!")
    print("=" * 60)
    print(f"\nğŸ“‚ DonnÃ©es disponibles dans: {DATA_CLEAN_DIR}")
    print("\nğŸ”œ Prochaine Ã©tape:")
    print("   python scripts/setup_db.py")
    print("   Puis charger les donnÃ©es nettoyÃ©es dans PostgreSQL")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
