"""
Script de chargement des donn√©es RetailRocket nettoy√©es dans PostgreSQL
"""

import os
import sys
from pathlib import Path
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Chemins
PROJECT_ROOT = Path(__file__).parent.parent
DATA_CLEAN_DIR = PROJECT_ROOT / "data" / "clean"

# Configuration de la base de donn√©es
DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://admin:admin123@localhost:5432/ecommerce_db')


def get_engine():
    """Cr√©er une connexion √† la base de donn√©es"""
    try:
        engine = create_engine(DATABASE_URL)
        # Tester la connexion
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        print("‚úì Connexion √† la base de donn√©es √©tablie")
        return engine
    except Exception as e:
        print(f"‚ùå Erreur de connexion √† la base de donn√©es: {e}")
        print("\nüí° Assurez-vous que PostgreSQL est d√©marr√©:")
        print("   docker-compose up -d postgres")
        sys.exit(1)


def load_csv_file(filename):
    """Charger un fichier CSV"""
    filepath = DATA_CLEAN_DIR / filename
    
    if not filepath.exists():
        print(f"  ‚ö†Ô∏è  Fichier non trouv√©: {filename}")
        return None
    
    try:
        df = pd.read_csv(filepath)
        print(f"  ‚úì {filename}: {len(df):,} lignes charg√©es")
        return df
    except Exception as e:
        print(f"  ‚ùå Erreur lors du chargement de {filename}: {e}")
        return None


def truncate_tables(engine, tables):
    """Vider les tables existantes"""
    print("\nüóëÔ∏è  Nettoyage des tables existantes...")
    
    with engine.connect() as conn:
        for table in tables:
            try:
                conn.execute(text(f"TRUNCATE TABLE {table} CASCADE"))
                conn.commit()
                print(f"  ‚úì Table {table} vid√©e")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Impossible de vider {table}: {e}")


def load_users(df, engine):
    """Charger les donn√©es utilisateurs"""
    if df is None:
        return
    
    print("\nüë• Chargement des utilisateurs...")
    
    # Adapter les colonnes au sch√©ma de la base
    df_users = pd.DataFrame({
        'user_id': df['user_id'],
        'email': df['user_id'].apply(lambda x: f'user{x}@retailrocket.com'),
        'created_at': df['first_visit'],
        'country': 'Unknown',  # Non disponible dans le dataset
        'segment': df['segment']
    })
    
    try:
        df_users.to_sql('users', engine, if_exists='append', index=False)
        print(f"  ‚úì {len(df_users):,} utilisateurs charg√©s")
    except Exception as e:
        print(f"  ‚ùå Erreur: {e}")


def load_products(df, engine):
    """Charger les donn√©es produits"""
    if df is None:
        return
    
    print("\nüì¶ Chargement des produits...")
    
    # Adapter les colonnes au sch√©ma de la base
    df_products = pd.DataFrame({
        'product_id': df['product_id'],
        'product_name': df['product_id'].apply(lambda x: f'Product {x}'),
        'category': 'General',  # Simplification
        'price': df.get('price', pd.Series([50.0] * len(df))),  # Prix par d√©faut si absent
        'stock': df.get('view_count', 100)  # Utiliser les vues comme proxy du stock
    })
    
    # Limiter aux 100k premiers produits pour √©viter les probl√®mes de m√©moire
    if len(df_products) > 100000:
        print(f"  ‚ö†Ô∏è  Limitation √† 100,000 produits (sur {len(df_products):,})")
        df_products = df_products.head(100000)
    
    try:
        df_products.to_sql('products', engine, if_exists='append', index=False)
        print(f"  ‚úì {len(df_products):,} produits charg√©s")
    except Exception as e:
        print(f"  ‚ùå Erreur: {e}")


def load_sessions(df, engine):
    """Charger les donn√©es de sessions"""
    if df is None:
        return
    
    print("\nüåê Chargement des sessions...")
    
    # Adapter les colonnes au sch√©ma de la base
    df_sessions = pd.DataFrame({
        'session_id': df['session_id'],
        'user_id': df['user_id'],
        'session_start': df['session_start'],
        'session_end': df.get('session_end'),
        'pages_viewed': df.get('events_count', 0),
        'device_type': 'Desktop',  # Non disponible dans le dataset
        'browser': 'Chrome'  # Non disponible dans le dataset
    })
    
    try:
        df_sessions.to_sql('sessions', engine, if_exists='append', index=False)
        print(f"  ‚úì {len(df_sessions):,} sessions charg√©es")
    except Exception as e:
        print(f"  ‚ùå Erreur: {e}")


def load_transactions(df, engine):
    """Charger les donn√©es de transactions"""
    if df is None:
        return
    
    print("\nüí≥ Chargement des transactions...")
    
    # Adapter les colonnes au sch√©ma de la base
    df_transactions = pd.DataFrame({
        'transaction_id': df['transaction_id'],
        'user_id': df['user_id'],
        'session_id': df.get('session_id'),
        'transaction_date': df['transaction_date'],
        'total_amount': df['amount'],
        'payment_method': 'Credit Card',
        'status': 'completed'
    })
    
    try:
        df_transactions.to_sql('transactions', engine, if_exists='append', index=False)
        print(f"  ‚úì {len(df_transactions):,} transactions charg√©es")
        print(f"  üí∞ CA total: {df_transactions['total_amount'].sum():,.2f}‚Ç¨")
    except Exception as e:
        print(f"  ‚ùå Erreur: {e}")


def load_transaction_items(df_transactions, engine):
    """Cr√©er les items de transaction"""
    if df_transactions is None:
        return
    
    print("\nüõí Cr√©ation des items de transaction...")
    
    # Cr√©er un item par transaction (simplification)
    df_items = pd.DataFrame({
        'transaction_id': df_transactions['transaction_id'],
        'product_id': df_transactions['product_id'],
        'quantity': 1,
        'unit_price': df_transactions['amount']
    })
    
    df_items['item_id'] = range(1, len(df_items) + 1)
    
    try:
        df_items.to_sql('transaction_items', engine, if_exists='append', index=False)
        print(f"  ‚úì {len(df_items):,} items charg√©s")
    except Exception as e:
        print(f"  ‚ùå Erreur: {e}")


def verify_data(engine):
    """V√©rifier les donn√©es charg√©es"""
    print("\nüîç V√©rification des donn√©es...")
    
    tables = ['users', 'products', 'sessions', 'transactions', 'transaction_items']
    
    with engine.connect() as conn:
        for table in tables:
            try:
                result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
                count = result.scalar()
                print(f"  ‚úì {table}: {count:,} enregistrements")
            except Exception as e:
                print(f"  ‚ùå {table}: Erreur - {e}")


def create_indexes(engine):
    """Cr√©er des index pour optimiser les performances"""
    print("\n‚ö° Cr√©ation des index...")
    
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_users_segment ON users(segment)",
        "CREATE INDEX IF NOT EXISTS idx_sessions_user_id ON sessions(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_sessions_date ON sessions(session_start)",
        "CREATE INDEX IF NOT EXISTS idx_transactions_user_id ON transactions(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_transactions_date ON transactions(transaction_date)",
        "CREATE INDEX IF NOT EXISTS idx_transaction_items_trans_id ON transaction_items(transaction_id)",
        "CREATE INDEX IF NOT EXISTS idx_transaction_items_product_id ON transaction_items(product_id)",
    ]
    
    with engine.connect() as conn:
        for idx_sql in indexes:
            try:
                conn.execute(text(idx_sql))
                conn.commit()
                print(f"  ‚úì Index cr√©√©")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Erreur: {e}")


def main():
    """Fonction principale"""
    print("=" * 60)
    print("  CHARGEMENT DES DONN√âES RETAILROCKET EN BASE")
    print("=" * 60)
    
    # Connexion √† la base
    engine = get_engine()
    
    # Charger les fichiers CSV
    print("\nüì• Chargement des fichiers CSV...")
    users_df = load_csv_file('users.csv')
    products_df = load_csv_file('products.csv')
    sessions_df = load_csv_file('sessions.csv')
    transactions_df = load_csv_file('transactions.csv')
    
    if not any([users_df is not None, transactions_df is not None]):
        print("\n‚ùå Aucune donn√©e √† charger")
        print("üí° Ex√©cutez d'abord: python scripts/preprocess_retailrocket.py")
        return 1
    
    # Vider les tables existantes
    truncate_tables(engine, [
        'transaction_items', 'transactions', 'sessions', 
        'products', 'users'
    ])
    
    # Charger les donn√©es
    load_users(users_df, engine)
    load_products(products_df, engine)
    load_sessions(sessions_df, engine)
    load_transactions(transactions_df, engine)
    load_transaction_items(transactions_df, engine)
    
    # V√©rifier les donn√©es
    verify_data(engine)
    
    # Cr√©er les index
    create_indexes(engine)
    
    print("\n" + "=" * 60)
    print("‚ú® CHARGEMENT TERMIN√â AVEC SUCC√àS!")
    print("=" * 60)
    print("\nüéâ Les donn√©es RetailRocket sont pr√™tes √† √™tre analys√©es!")
    print("\nüîú Prochaine √©tape:")
    print("   D√©marrer le dashboard: docker-compose up -d dash-app")
    print("   Acc√©der √†: http://localhost:8050")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
