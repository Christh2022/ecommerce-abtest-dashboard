# E-commerce Dashboard & A/B Testing ğŸš€

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Dash](https://img.shields.io/badge/Dash-2.14.2-brightgreen.svg)](https://dash.plotly.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-success.svg)](https://github.com/Christh2022/ecommerce-abtest-dashboard)

> ğŸ¤ **Nouveau : Interface vocale interactive !** L'application intÃ¨gre maintenant la reconnaissance vocale pour une navigation mains-libres. Dites "Explique l'accueil" pour une prÃ©sentation guidÃ©e !

Plateforme d'analyse e-commerce avec dashboard interactif, assistant vocal intelligent et outils d'A/B testing utilisant Python, Dash, PostgreSQL, Docker et Grafana.

## ğŸ“Š Vue d'ensemble

Ce projet analyse les donnÃ©es du dataset **RetailRocket** (2.7M Ã©vÃ©nements, 1.4M utilisateurs, 235K produits) pour crÃ©er un dashboard de visualisation et des outils d'analyse de performance e-commerce.

### âœ¨ FonctionnalitÃ©s Principales

- ğŸ“ˆ **Dashboard interactif** : 12+ pages de visualisation en temps rÃ©el des KPIs e-commerce
- ğŸ¤ **Assistant Vocal Intelligent** : Navigation vocale, explications guidÃ©es et commandes mains-libres
- ğŸ§ª **A/B Testing** : 16 scÃ©narios de test simulÃ©s avec analyse statistique complÃ¨te
- ğŸ“‰ **Analyse de tendances** : MÃ©triques quotidiennes, entonnoirs de conversion, performance produits
- ğŸ¯ **MÃ©thodologie** : Guide complet des bonnes pratiques en A/B testing
- ğŸ³ **DÃ©ploiement** : Application containerisÃ©e avec Docker, PostgreSQL et Grafana
- ğŸ›¡ï¸ **SÃ©curitÃ©** : Protection multicouche, tests automatisÃ©s, monitoring temps rÃ©el

### ğŸ¤ Assistant Vocal - Nouvelle FonctionnalitÃ© !

L'application intÃ¨gre un **systÃ¨me de reconnaissance vocale** pour une expÃ©rience utilisateur rÃ©volutionnaire :

**FonctionnalitÃ©s vocales :**

- ğŸ—£ï¸ **Accueil personnalisÃ©** : "Bonjour Docteur Christh, comment puis-je vous aider ?"
- ğŸ“š **Explications dÃ©taillÃ©es** : Dites "Explique l'accueil" pour une prÃ©sentation complÃ¨te
- ğŸ§­ **Navigation vocale** : "Va sur le dashboard" ou "Montre-moi les conversions"
- ğŸ”„ **Interaction continue** : L'assistant Ã©coute et rÃ©pond en boucle

**Commandes vocales disponibles :**

```
"Explique l'accueil" / "Explique l'application" â†’ PrÃ©sentation dÃ©taillÃ©e de la plateforme
"Dashboard" / "Tableau de bord" â†’ Redirection vers le dashboard principal
"Connexion" / "Connecter" â†’ Redirection vers la page de connexion
```

**CompatibilitÃ© :** Chrome, Edge, Safari (Web Speech API)

**Essayez maintenant :** Ouvrez http://localhost:8050 et parlez ! ğŸ™ï¸

## ğŸ›¡ï¸ SÃ©curitÃ© - Important pour les Collaborateurs

**ğŸ“– [GUIDE COMPLET DE SÃ‰CURITÃ‰ â†’](SECURITY_GUIDE_COLLABORATORS.md)** (Lecture obligatoire)

### Protections Actives

âœ… **Authentification** : Flask-Login + bcrypt  
âœ… **Anti-DDoS** : Rate limiting 200 req/min (94.4% d'efficacitÃ© testÃ©e)  
âœ… **En-tÃªtes HTTP** : CSP, X-Frame-Options, X-Content-Type-Options, etc.  
âœ… **Tests automatisÃ©s** : 41 types d'attaques (SQL injection, XSS, CSRF...)  
âœ… **Monitoring** : Grafana + 32 alertes en temps rÃ©el

### ğŸ§ª Tests de l'Application

#### Lancer la Suite de Tests ComplÃ¨te

```bash
# Windows
bin\run_tests.bat

# Linux/Mac
./bin/run_tests.sh

# Ou directement avec Python
python run_tests.py
```

**Ce qui est testÃ©** :

- âœ… Connexion au serveur (port 8050)
- âœ… Page d'accueil publique (landing page)
- âœ… Page de connexion
- âœ… SystÃ¨me d'authentification
- âœ… Protection des pages sÃ©curisÃ©es
- âœ… Services Docker (dash-app, postgres, grafana, prometheus)

**ğŸ“Š RÃ©sultat attendu** :

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   E-Commerce A/B Test Dashboard - Suite de tests         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ PASS      Connexion serveur
âœ“ PASS      Landing page
âœ“ PASS      Page de connexion
âœ“ PASS      Authentification
âœ“ PASS      Pages protÃ©gÃ©es
âœ“ PASS      Services Docker

RÃ©sultat: 6/6 tests rÃ©ussis
ğŸ‰ Tous les tests sont passÃ©s !
```

**âš™ï¸ Configuration** : Modifiez `run_tests.py` si vous avez changÃ© les identifiants par dÃ©faut :

```python
TEST_USER = {
    "username": "admin",
    "password": "admin123"  # Ã€ modifier selon votre configuration
}
```

**ğŸ“š Plus d'informations** : Consultez le [Guide SÃ©curitÃ© Collaborateurs](SECURITY_GUIDE_COLLABORATORS.md) pour :

- ProcÃ©dures de test complÃ¨tes
- Bonnes pratiques de dÃ©veloppement sÃ©curisÃ©
- Que faire en cas d'incident de sÃ©curitÃ©
- Ressources de formation cybersÃ©curitÃ©

---

## ğŸš€ DÃ©marrage Rapide - Guide Collaborateur

### âš¡ Installation en 5 Minutes

#### 1ï¸âƒ£ PrÃ©requis (Ã  installer avant de commencer)

| Logiciel       | Version minimum | Lien de tÃ©lÃ©chargement                                                               | VÃ©rification       |
| -------------- | --------------- | ------------------------------------------------------------------------------------ | ------------------ |
| Docker Desktop | 24.0+           | [docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop) | `docker --version` |
| Git            | 2.40+           | [git-scm.com/downloads](https://git-scm.com/downloads)                               | `git --version`    |
| Python         | 3.10+           | [python.org](https://www.python.org/downloads/)                                      | `python --version` |

**Configuration systÃ¨me requise** :

- ğŸ’¾ RAM : Minimum 4 GB disponible (8 GB recommandÃ©)
- ğŸ’¿ Espace disque : 5 GB libre
- ğŸŒ Connexion Internet (pour le premier dÃ©marrage)

#### 2ï¸âƒ£ Cloner le Projet

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/Christh2022/ecommerce-abtest-dashboard.git

# Aller dans le rÃ©pertoire
cd ecommerce-abtest-dashboard

# VÃ©rifier que vous Ãªtes sur la bonne branche
git branch
```

#### 3ï¸âƒ£ Installer les DÃ©pendances Python

```bash
# CrÃ©er un environnement virtuel (optionnel mais recommandÃ©)
python -m venv venv

# Activer l'environnement virtuel
# Windows :
venv\Scripts\activate
# Linux/Mac :
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Lancer les Services Docker

```bash
# DÃ©marrer tous les conteneurs
docker compose -f docker-compose.secure.yml up -d --build

# â±ï¸ Attendre 2-3 minutes que tous les services dÃ©marrent
```

**Ce qui se passe en arriÃ¨re-plan** :

- ğŸ³ Construction des images Docker personnalisÃ©es
- ğŸ—„ï¸ CrÃ©ation de la base de donnÃ©es PostgreSQL
- ğŸ“Š DÃ©marrage de Grafana pour la visualisation
- ğŸ” Lancement de Prometheus pour les mÃ©triques
- ğŸ“ Initialisation de Loki pour les logs
- ğŸ¨ DÃ©marrage de l'application Dash

#### 5ï¸âƒ£ VÃ©rifier que Tout Fonctionne

```bash
# VÃ©rifier l'Ã©tat des services (tous doivent Ãªtre "Up" et "healthy")
docker compose -f docker-compose.secure.yml ps

# Vous devriez voir 7-8 conteneurs en cours d'exÃ©cution :
# âœ… ecommerce-dashboard (healthy)
# âœ… ecommerce-postgres (healthy)
# âœ… ecommerce-grafana (healthy)
# âœ… ecommerce-prometheus (healthy)
# âœ… ecommerce-loki
# âœ… ecommerce-promtail
# âœ… ecommerce-exporter
# âœ… ecommerce-postgres-exporter
```

#### 6ï¸âƒ£ Importer les DonnÃ©es (IMPORTANT !)

Les tables PostgreSQL sont crÃ©Ã©es automatiquement mais **vides**. Vous devez charger les donnÃ©es.

**âš ï¸ ATTENTION** : Sur Windows, l'option `-w /` peut causer une erreur. Utilisez la mÃ©thode ci-dessous qui fonctionne sur **tous les systÃ¨mes** :

```bash
# Ã‰tape 1 : Copier les scripts et donnÃ©es nÃ©cessaires
docker cp scripts/import_data_to_postgres.py ecommerce-dashboard:/tmp/
docker cp scripts/fix_numeric_overflow.py ecommerce-dashboard:/tmp/
docker cp data/clean ecommerce-dashboard:/tmp/data

# Ã‰tape 2 : Corriger le schÃ©ma de la base de donnÃ©es (OBLIGATOIRE)
# Cette Ã©tape corrige les colonnes NUMERIC(5,4) qui ne peuvent pas stocker les pourcentages (0-100)
docker exec -e DB_HOST=postgres ecommerce-dashboard sh -c "cd /tmp && python fix_numeric_overflow.py"

# Vous devriez voir :
# âœ… user_behavior.bounce_rate â†’ NUMERIC(6,2)
# âœ… products_summary.conversion_rate â†’ NUMERIC(6,2)
# âœ… ab_test_results.conversion_rate â†’ NUMERIC(6,2)
# âœ… ab_test_results.statistical_significance â†’ NUMERIC(6,2)
# âœ… funnel_stages.conversion_rate â†’ NUMERIC(6,2)

# Ã‰tape 3 : ExÃ©cuter l'import des donnÃ©es
docker exec -e DB_HOST=postgres ecommerce-dashboard sh -c "
cd /tmp &&
sed 's|Path(__file__).parent.parent / '\''data'\'' / '\''clean'\''|Path('\''/tmp/data'\'')|g' import_data_to_postgres.py > import_fixed.py &&
python import_fixed.py
"

# Ã‰tape 4 : âœ… VÃ©rifier que l'import a rÃ©ussi
docker exec -e DB_HOST=postgres ecommerce-dashboard python -c "import psycopg2; conn = psycopg2.connect(host='postgres', database='ecommerce_db', user='dashuser', password='dashpass'); cur = conn.cursor(); cur.execute('SELECT COUNT(*) FROM daily_metrics'); dm = cur.fetchone()[0]; cur.execute('SELECT COUNT(*) FROM products_summary'); ps = cur.fetchone()[0]; cur.execute('SELECT COUNT(*) FROM funnel_stages'); fs = cur.fetchone()[0]; cur.execute('SELECT COUNT(*) FROM ab_test_results'); ab = cur.fetchone()[0]; cur.execute('SELECT COUNT(*) FROM traffic_sources'); ts = cur.fetchone()[0]; print(f'âœ… daily_metrics: {dm} rows'); print(f'âœ… products_summary: {ps:,} rows'); print(f'âœ… funnel_stages: {fs} rows'); print(f'âœ… ab_test_results: {ab} rows'); print(f'âœ… traffic_sources: {ts} rows')"
```

**âœ… RÃ©sultat attendu** :

```
âœ… daily_metrics: 139 rows
âœ… products_summary: 235,061 rows
âœ… funnel_stages: 417 rows
âœ… ab_test_results: 480 rows
âœ… traffic_sources: 139 rows
```

**â±ï¸ DurÃ©e de l'import** : ~2 minutes (correction schÃ©ma) + ~2 minutes (import des donnÃ©es)

**ğŸ’¡ Note importante** : La correction du schÃ©ma (Ã‰tape 2) est **obligatoire** et doit Ãªtre exÃ©cutÃ©e **avant** l'import des donnÃ©es. Elle modifie les colonnes de pourcentage de NUMERIC(5,4) Ã  NUMERIC(6,2) pour permettre le stockage de valeurs de 0 Ã  100.

**ğŸ”§ RÃ©solution des problÃ¨mes courants** :

<details>
<summary>âŒ Erreur "numeric field overflow" (si Ã‰tape 2 non exÃ©cutÃ©e)</summary>

Si vous avez oubliÃ© l'Ã‰tape 2, vous verrez cette erreur :

```
psycopg2.errors.NumericValueOutOfRange: numeric field overflow
DETAIL: A field with precision 5, scale 4 must round to an absolute value less than 10^1.
```

**Solution** : Retournez Ã  l'Ã‰tape 2 et exÃ©cutez le script de correction du schÃ©ma :

```bash
docker exec -e DB_HOST=postgres ecommerce-dashboard sh -c "cd /tmp && python fix_numeric_overflow.py"
```

Puis relancez l'import (Ã‰tape 3).

</details>

<details>
<summary>âŒ Erreur "CSV not found" lors de l'import</summary>

VÃ©rifiez que les fichiers CSV sont bien copiÃ©s :

```bash
# VÃ©rifier que les fichiers sont prÃ©sents
docker exec ecommerce-dashboard sh -c "ls -la /tmp/data/*.csv | head -10"

# Vous devriez voir : daily_metrics.csv, products_summary.csv, etc.
```

Si les fichiers ne sont pas lÃ , recommencez l'Ã‰tape 1 (docker cp).

</details>

**ğŸ’¡ Pourquoi cette mÃ©thode ?** : L'import se fait depuis l'intÃ©rieur du rÃ©seau Docker, ce qui Ã©vite les problÃ¨mes de connexion localhost sur Windows et les problÃ¨mes de chemins relatifs. La correction du schÃ©ma est nÃ©cessaire car les donnÃ©es de pourcentage sont stockÃ©es au format 0-100 et non 0.00-1.00.

#### 7ï¸âƒ£ CrÃ©er les Dashboards Grafana

Les dashboards Grafana doivent Ãªtre crÃ©Ã©s aprÃ¨s l'import des donnÃ©es (prend ~2 minutes).

**ğŸ¯ MÃ©thode 1 : Script Automatique (RecommandÃ©)**

```bash
# Windows
bin\run_all_dashboards.bat

# Linux/Mac
./bin/run_all_dashboards.sh

# Ou directement avec Python
python run_all_dashboards.py
```

Ce script exÃ©cute automatiquement tous les scripts de crÃ©ation de dashboards dans l'ordre avec un rÃ©sumÃ© dÃ©taillÃ©.

**ğŸ”§ MÃ©thode 2 : ExÃ©cution Manuelle**

```bash
# Installer les dÃ©pendances si nÃ©cessaire
pip install requests python-dotenv

# ExÃ©cuter tous les scripts de crÃ©ation de dashboards
python grafana_dashboards_scripts/create_dashboards_1_3.py
python grafana_dashboards_scripts/create_dashboards_4_6.py
python grafana_dashboards_scripts/create_bi_dashboard.py
python grafana_dashboards_scripts/create_full_dashboard.py
python grafana_dashboards_scripts/create_monitoring_dashboard.py
python grafana_dashboards_scripts/create_prometheus_dashboard.py
```

**âœ… Messages de confirmation attendus** :

```
âœ“ Product Performance Analysis created successfully
âœ“ Customer Segmentation Analysis created successfully
âœ“ Customer Journey & Funnel Analysis created successfully
âœ“ E-Commerce A/B Test Analytics created successfully
âœ“ Cohort Analysis & Retention created successfully
âœ“ Predictive Analytics & Forecasting created successfully
âœ“ Business Intelligence & Decision Support created successfully
âœ“ E-Commerce Full Overview Dashboard created successfully
âœ“ E-Commerce Monitoring Dashboard created successfully
âœ“ E-Commerce Dashboard (Prometheus) created successfully
```

**ğŸ“Š Dashboards crÃ©Ã©s (10 au total)** :

1. Product Performance Analysis
2. Customer Segmentation Analysis
3. Customer Journey & Funnel Analysis
4. E-Commerce A/B Test Analytics
5. Cohort Analysis & Retention
6. Predictive Analytics & Forecasting
7. Business Intelligence & Decision Support
8. E-Commerce Full Overview Dashboard
9. E-Commerce Monitoring Dashboard
10. E-Commerce Dashboard (Prometheus)

**ğŸ”§ En cas d'erreur** :

```bash
# VÃ©rifier que Grafana est accessible
curl http://localhost:3000/api/health

# VÃ©rifier les identifiants Grafana
# Par dÃ©faut : admin / admin123
```

**âœ… Messages de confirmation attendus** :

```
âœ“ Product Performance Analysis created successfully
âœ“ Customer Segmentation Analysis created successfully
âœ“ Customer Journey & Funnel Analysis created successfully
âœ“ E-Commerce A/B Test Analytics created successfully
âœ“ Cohort Analysis & Retention created successfully
âœ“ Predictive Analytics & Forecasting created successfully
âœ“ Business Intelligence & Decision Support created successfully
âœ“ E-Commerce Full Overview Dashboard created successfully
âœ“ E-Commerce Monitoring Dashboard created successfully
âœ“ E-Commerce Dashboard (Prometheus) created successfully
```

**ğŸ“Š Dashboards crÃ©Ã©s (10 au total)** :

1. Product Performance Analysis
2. Customer Segmentation Analysis
3. Customer Journey & Funnel Analysis
4. E-Commerce A/B Test Analytics
5. Cohort Analysis & Retention
6. Predictive Analytics & Forecasting
7. Business Intelligence & Decision Support
8. E-Commerce Full Overview Dashboard
9. E-Commerce Monitoring Dashboard
10. E-Commerce Dashboard (Prometheus)

**ğŸ”§ En cas d'erreur** :

```bash
# VÃ©rifier que Grafana est accessible
curl http://localhost:3000/api/health

# VÃ©rifier les identifiants Grafana
# Par dÃ©faut : admin / admin123
```

#### 8ï¸âƒ£ AccÃ©der aux Applications

| Application           | URL                                            | Identifiants        | Description                                            |
| --------------------- | ---------------------------------------------- | ------------------- | ------------------------------------------------------ |
| ğŸ¨ **Dashboard Dash** | [http://localhost:8050](http://localhost:8050) | admin / admin123    | Application principale avec 12 pages + Assistant Vocal |
| ğŸ“Š **Grafana**        | [http://localhost:3000](http://localhost:3000) | admin / admin123    | 10 dashboards de monitoring                            |
| ğŸ” **Prometheus**     | [http://localhost:9090](http://localhost:9090) | Aucun               | MÃ©triques en temps rÃ©el                                |
| ğŸ—„ï¸ **PostgreSQL**     | localhost:5432                                 | dashuser / dashpass | Base de donnÃ©es (connexion via client SQL)             |

> **ğŸ¤ Astuce :** Une fois sur http://localhost:8050, cliquez sur la page puis dites "Explique l'accueil" pour dÃ©couvrir toutes les fonctionnalitÃ©s !

---

### ğŸ¯ Tester que Tout Fonctionne

**Test 1 : Dashboard Dash**

1. Ouvrir http://localhost:8050
2. Vous devriez voir la page d'accueil avec des KPIs

**Test 2 : Grafana**

1. Ouvrir http://localhost:3000
2. Se connecter avec admin / admin123
3. Aller dans Dashboards â†’ Vous devriez voir 10 dashboards

**Test 3 : DonnÃ©es PostgreSQL**

```bash
# VÃ©rifier le nombre de produits
docker exec ecommerce-postgres psql -U dashuser -d ecommerce_db -c "SELECT COUNT(*) as nb_produits FROM products_summary;"
# Devrait afficher un nombre > 0
```

---

### ï¿½ Tests de SÃ©curitÃ© AutomatisÃ©s

Le projet inclut un systÃ¨me complet de **dÃ©tection d'attaques en temps rÃ©el** avec 41 types d'attaques simulÃ©es et monitoring via Grafana.

#### ğŸš€ Lancement Rapide des Tests de SÃ©curitÃ©

**Windows** :

```bash
# Double-cliquer sur le fichier ou exÃ©cuter dans cmd :
lancer_tests_securite.bat
```

**Linux/Mac** :

```bash
# Rendre le script exÃ©cutable et lancer :
chmod +x lancer_tests_securite.sh
./lancer_tests_securite.sh
```

Le script effectue automatiquement :

1. âœ… VÃ©rification des services (Dashboard, Prometheus, Pushgateway)
2. ğŸ¯ Lancement de 41 tests d'attaque sur l'application
3. ğŸ“Š Envoi des mÃ©triques vers Prometheus
4. ğŸ“ˆ Affichage du rÃ©sumÃ© des rÃ©sultats

#### ğŸ“Š Visualisation des Alertes dans Grafana

**AccÃ©der au Dashboard de SÃ©curitÃ©** :

1. Ouvrir [http://localhost:3000](http://localhost:3000)
2. Se connecter avec `admin` / `admin123`
3. Aller dans **Dashboards** â†’ **Security Attacks - Real-time Monitoring**

**Dashboard inclut 8 panneaux** :

- ğŸ¯ Compteur total des attaques dÃ©tectÃ©es
- ğŸ”´ Attaques critiques (SQL injection, Command injection, etc.)
- ğŸŸ  Attaques haute sÃ©vÃ©ritÃ© (XSS, CSRF, etc.)
- ğŸŸ¡ Attaques moyenne sÃ©vÃ©ritÃ© (Information disclosure, etc.)
- ğŸ“ˆ Taux d'attaques par minute
- ğŸ“Š Distribution par catÃ©gorie et sÃ©vÃ©ritÃ©
- ğŸ“‹ Tableau des 20 derniÃ¨res attaques

#### ğŸš¨ RÃ¨gles d'Alerte ConfigurÃ©es

**32+ rÃ¨gles d'alerte actives** incluant :

- ğŸ”´ **Critical** : SQL Injection, Command Injection, Path Traversal
- ğŸŸ  **High** : XSS, CSRF, File Upload, Authentication Bypass
- ğŸŸ¡ **Medium** : Information Disclosure, Weak Cryptography

Les alertes se dÃ©clenchent **30-60 secondes** aprÃ¨s dÃ©tection d'une attaque.

#### ğŸ” Types d'Attaques TestÃ©es (41 au total)

| CatÃ©gorie                   | Nombre | Exemples                                     |
| --------------------------- | ------ | -------------------------------------------- |
| ğŸ—„ï¸ Injection SQL            | 5      | UNION attacks, Blind SQL, Time-based SQLi    |
| ğŸ’» Injection de Commandes   | 3      | OS command injection, Shell injection        |
| ğŸŒ Cross-Site Scripting     | 4      | Stored XSS, Reflected XSS, DOM XSS           |
| ğŸ” Authentification         | 6      | Brute force, Session hijacking, Token bypass |
| ğŸ“ Manipulation de Fichiers | 5      | Path traversal, File upload, LFI/RFI         |
| ğŸ”’ SÃ©curitÃ© Session         | 4      | Session fixation, Cookie hijacking           |
| ğŸ›¡ï¸ CSRF                     | 3      | Token bypass, Same-site bypass               |
| ğŸ“Š Information Disclosure   | 4      | Error exposure, Directory listing            |
| ğŸ”“ Access Control           | 3      | IDOR, Privilege escalation                   |
| âš¡ DoS/Resource Abuse       | 4      | Rate limit bypass, Resource exhaustion       |

#### ğŸ› ï¸ Test Manuel (avancÃ©)

```bash
# Activer l'environnement virtuel
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Lancer les tests
python test_security_simple.py

# RÃ©sultats attendus :
# âœ… 41 attaques testÃ©es
# âœ… MÃ©triques envoyÃ©es Ã  Prometheus
# âœ… Rapports gÃ©nÃ©rÃ©s dans security-reports/attack-results/
```

#### ğŸ“ Fichiers et Documentation

- `test_security_simple.py` - Script de test principal (41 attaques)
- `GUIDE_COLLABORATEURS.md` - Guide complet pour collaborateurs
- `grafana/dashboards/security-attacks-realtime.json` - Dashboard Grafana
- `grafana/provisioning/alerting/attack-alerts.yml` - RÃ¨gles d'alerte (32+)
- `security-reports/attack-results/` - Rapports JSON des tests

#### âš ï¸ Notes Importantes

- Les tests sont **non destructifs** et utilisent l'endpoint `/health` de l'application
- Toutes les attaques sont **simulÃ©es** et **loggÃ©es** uniquement
- Les mÃ©triques sont conservÃ©es dans Prometheus pendant 15 jours
- Falco n'est pas disponible sur WSL2 (incompatibilitÃ© kernel)

---

### ï¿½ğŸ› ï¸ Commandes Utiles au Quotidien

#### RedÃ©marrer les Services

```bash
# RedÃ©marrer tous les services
docker compose -f docker-compose.secure.yml restart

# RedÃ©marrer un service spÃ©cifique
docker compose -f docker-compose.secure.yml restart grafana
```

#### Voir les Logs

```bash
# Logs de tous les services
docker compose -f docker-compose.secure.yml logs -f

# Logs d'un service spÃ©cifique
docker logs ecommerce-dashboard -f
docker logs ecommerce-postgres -f
docker logs ecommerce-grafana -f
```

#### ArrÃªter les Services

```bash
# ArrÃªter sans supprimer les donnÃ©es
docker compose -f docker-compose.secure.yml down

# ArrÃªter ET supprimer toutes les donnÃ©es (âš ï¸ ATTENTION)
docker compose -f docker-compose.secure.yml down -v
```

#### Reconstruire aprÃ¨s Modifications du Code

```bash
# Reconstruire et redÃ©marrer
docker compose -f docker-compose.secure.yml up -d --build

# Forcer la reconstruction complÃ¨te
docker compose -f docker-compose.secure.yml build --no-cache
docker compose -f docker-compose.secure.yml up -d
```

---

### ğŸ†˜ RÃ©solution des ProblÃ¨mes Courants

#### âŒ ProblÃ¨me : "Port already in use"

```bash
# Trouver quel processus utilise le port
# Windows :
netstat -ano | findstr :8050
netstat -ano | findstr :3000

# Linux/Mac :
lsof -i :8050
lsof -i :3000

# Solution : ArrÃªter le processus ou changer le port dans docker-compose.secure.yml
```

#### âŒ ProblÃ¨me : "Container is unhealthy"

```bash
# Voir les dÃ©tails de santÃ© du conteneur
docker inspect ecommerce-postgres --format='{{.State.Health}}'

# Voir les logs pour comprendre le problÃ¨me
docker logs ecommerce-postgres --tail 50

# Solution : RedÃ©marrer le conteneur problÃ©matique
docker compose -f docker-compose.secure.yml restart postgres
```

#### âŒ ProblÃ¨me : "No data in Grafana dashboards"

```bash
# 1. VÃ©rifier que PostgreSQL contient des donnÃ©es
docker exec -e DB_HOST=postgres ecommerce-dashboard python -c "import psycopg2; conn = psycopg2.connect(host='postgres', database='ecommerce_db', user='dashuser', password='dashpass'); cur = conn.cursor(); cur.execute('SELECT COUNT(*) FROM daily_metrics'); print(f'daily_metrics: {cur.fetchone()[0]} rows'); cur.execute('SELECT COUNT(*) FROM products_summary'); print(f'products_summary: {cur.fetchone()[0]} rows')"

# Si le rÃ©sultat est 0, refaites l'import des donnÃ©es (Ã‰tape 6)

# 2. VÃ©rifier que l'exporter Prometheus fonctionne
curl http://localhost:9200/metrics 2>/dev/null | grep ecommerce

# 3. VÃ©rifier que Prometheus scrape l'exporter
# Ouvrir http://localhost:9090/targets et vÃ©rifier que "ecommerce-exporter" est UP

# 4. RecrÃ©er les dashboards Grafana si nÃ©cessaire (Ã‰tape 7)
python grafana_dashboards_scripts/create_dashboards_1_3.py
python grafana_dashboards_scripts/create_dashboards_4_6.py
# ... (tous les autres scripts)
```

#### âŒ ProblÃ¨me : "Cannot import psycopg2" lors de la crÃ©ation des dashboards

```bash
# Installer les dÃ©pendances Python localement
pip install psycopg2-binary requests python-dotenv

# RÃ©essayer la crÃ©ation des dashboards
python grafana_dashboards_scripts/create_dashboards_1_3.py
```

**Note** : Cette erreur apparaÃ®t uniquement lors de l'exÃ©cution des scripts de crÃ©ation de dashboards Grafana depuis votre machine locale, pas lors de l'import des donnÃ©es qui s'exÃ©cute dans le conteneur Docker.

---

### ğŸ“š Structure du Projet

```
ecommerce-abtest-dashboard/
â”œâ”€â”€ dashboard/              # Application Dash (Frontend)
â”‚   â”œâ”€â”€ app.py             # Point d'entrÃ©e principal
â”‚   â”œâ”€â”€ pages/             # Pages du dashboard
â”‚   â””â”€â”€ components/        # Composants rÃ©utilisables
â”œâ”€â”€ data/
â”‚   â””â”€â”€ clean/             # DonnÃ©es CSV nettoyÃ©es
â”œâ”€â”€ docker/                # ğŸ†• Dockerfiles du projet
â”‚   â”œâ”€â”€ Dockerfile         # Image principale Dash
â”‚   â”œâ”€â”€ Dockerfile.exporter        # Image exporteur Prometheus
â”‚   â”œâ”€â”€ Dockerfile.dashboard-init  # Image init dashboards
â”‚   â””â”€â”€ README.md          # Documentation des Dockerfiles
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/        # Fichiers JSON des dashboards
â”‚   â””â”€â”€ provisioning/      # Configuration Grafana
â”œâ”€â”€ grafana_dashboards_scripts/  # ğŸ†• Scripts de crÃ©ation des dashboards
â”‚   â”œâ”€â”€ create_dashboards_1_3.py # Dashboards 1-3
â”‚   â”œâ”€â”€ create_dashboards_4_6.py # Dashboards 4-6
â”‚   â”œâ”€â”€ create_bi_dashboard.py   # BI Dashboard
â”‚   â”œâ”€â”€ create_full_dashboard.py # Full Dashboard
â”‚   â”œâ”€â”€ create_monitoring_dashboard.py
â”‚   â”œâ”€â”€ create_prometheus_dashboard.py
â”‚   â””â”€â”€ README.md          # Documentation des scripts
â”œâ”€â”€ bin/                   # ğŸ†• Scripts exÃ©cutables
â”‚   â”œâ”€â”€ run_all_dashboards.bat   # Windows - CrÃ©er dashboards
â”‚   â”œâ”€â”€ run_all_dashboards.sh    # Linux/Mac - CrÃ©er dashboards
â”‚   â”œâ”€â”€ run_tests.bat            # Windows - Lancer tests
â”‚   â”œâ”€â”€ run_tests.sh             # Linux/Mac - Lancer tests
â”‚   â””â”€â”€ README.md          # Documentation des scripts
â”œâ”€â”€ scripts/               # Scripts d'import et d'analyse
â”‚   â”œâ”€â”€ import_data_to_postgres.py  # Import des donnÃ©es
â”‚   â””â”€â”€ init_db.sql        # Initialisation de la DB
â”œâ”€â”€ run_all_dashboards.py  # Script Python pour crÃ©er tous les dashboards
â”œâ”€â”€ docker-compose.secure.yml  # Configuration Docker
â””â”€â”€ README.md              # Ce fichier
```

**ğŸ†• NouveautÃ©s** : 
- Les scripts de crÃ©ation de dashboards Grafana sont organisÃ©s dans `grafana_dashboards_scripts/`
- Les Dockerfiles sont regroupÃ©s dans `docker/`
- Les scripts exÃ©cutables (.bat/.sh) sont dans `bin/`

---

### ğŸ¤ Contribution

Pour contribuer au projet :

1. CrÃ©er une branche : `git checkout -b feature/ma-fonctionnalite`
2. Faire vos modifications
3. Tester localement : `docker compose -f docker-compose.secure.yml up -d --build`
4. Commit : `git commit -m "feat: description"`
5. Push : `git push origin feature/ma-fonctionnalite`
6. CrÃ©er une Pull Request sur GitHub

---

### ğŸ“ Support

- ğŸ“§ Email : [votre-email@example.com]
- ğŸ’¬ Slack : #ecommerce-dashboard
- ğŸ“– Documentation complÃ¨te : [docs/README.md](docs/)

---

---

## âœ¨ DÃ©mo en Ligne

**Dashboard accessible Ã ** : http://localhost:8050

**Pages disponibles** :

- ğŸ  Accueil - Vue d'ensemble et KPIs
- ğŸ‘¥ Trafic - Analyse des visiteurs
- ğŸ–±ï¸ Comportement - Patterns d'engagement
- ğŸ›’ Conversions - Funnel analysis
- ğŸ“¦ Produits - Performance et Pareto
- ğŸ”„ Funnel - Visualisation tunnel
- ğŸ§ª Simulations A/B - 16 scÃ©narios
- ğŸ“Š RÃ©sultats A/B - Analyse statistique
- ğŸ§® Calculateur Z-Test - Outil interactif
- ğŸ“ˆ Visualisations - Graphiques avancÃ©s
- ğŸ“š MÃ©thodologie - Guide complet
- â„¹ï¸ Ã€ Propos - Documentation projet

**Grafana Dashboards** : http://localhost:3000 (admin/admin123)

AprÃ¨s avoir exÃ©cutÃ© les scripts ci-dessus, vous aurez accÃ¨s Ã  10 dashboards :

- Business Intelligence & Decision Support
- Cohort Analysis & Retention
- Customer Journey & Funnel Analysis
- Customer Segmentation Analysis
- E-Commerce A/B Test Analytics
- E-Commerce Dashboard (Prometheus)
- E-Commerce Monitoring Dashboard
- Predictive Analytics & Forecasting
- Product Performance Analysis
- Real-Time Performance Monitoring

---

## ğŸ¯ Milestone 1 : Dataset & PrÃ©paration des DonnÃ©es âœ…

**Statut** : COMPLÃ‰TÃ‰ (8 issues)  
**Branche** : `feature/data-preprocessing`  
**PÃ©riode** : DÃ©cembre 2025

### ğŸ“¦ Dataset RetailRocket

Source : [Kaggle - RetailRocket E-commerce Dataset](https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset)

**CaractÃ©ristiques :**

- **PÃ©riode couverte** : 2015-05-03 â†’ 2015-09-18 (137 jours / 19.6 semaines)
- **Ã‰vÃ©nements totaux** : 2,755,641 (aprÃ¨s nettoyage)
  - Views : 2,664,218 (96.7%)
  - Add-to-carts : 68,966 (2.5%)
  - Transactions : 22,457 (0.8%)
- **Utilisateurs uniques** : 1,407,580
- **Sessions uniques** : 1,649,534
- **Produits uniques** : 235,061
- **Revenu total** : 5,732,867.82 â‚¬
- **Taux de conversion global** : 0.84%

---

## ğŸ”§ Issues ComplÃ©tÃ©es

### Issue #1 : TÃ©lÃ©charger le dataset RetailRocket âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/download_data.py` : Script de tÃ©lÃ©chargement via Kaggle API
- DonnÃ©es brutes (942 MB) â†’ nettoyÃ©es (536 MB)

### Issue #2 : Inspecter les fichiers CSV âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/inspect_csv.py` : Analyse exploratoire des donnÃ©es
- RÃ©sultats : 460 doublons dÃ©tectÃ©s dans `events.csv`

### Issue #3 : Nettoyer events.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/clean_events.py` : Suppression des doublons
- `data/clean/events_cleaned.csv` : 2,755,641 lignes (460 doublons supprimÃ©s)

### Issue #4 : Nettoyer item_properties.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/clean_item_properties.py` : Parsing et structuration
- `data/clean/item_properties_cleaned.csv` : 20,275,902 lignes, 9 colonnes typÃ©es

### Issue #5 : Fusionner les donnÃ©es âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/merge_data.py` : Fusion et enrichissement (515 lignes)
- **8 tables enrichies** (490 MB total) :
  - `events_enriched.csv` : 2.7M lignes, 12 colonnes (242 MB)
  - `sessions_enriched.csv` : 1.6M lignes, 10 colonnes (134 MB)
  - `transactions_enriched.csv` : 22K lignes, 13 colonnes (2 MB)
  - `daily_funnel.csv` : 139 jours, entonnoir de conversion
  - `hourly_analysis.csv` : 24 heures, activitÃ© horaire
  - `segment_performance.csv` : 4 segments utilisateurs
  - `user_journey.csv` : 1.4M parcours (105 MB)
  - `product_performance.csv` : 235K produits (7.5 MB)

### Issue #6 : GÃ©nÃ©rer data_clean.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/generate_data_clean_simple.py` : Consolidation optimisÃ©e par chunks
- `data/clean/data_clean.csv` : 2.7M lignes, 13 colonnes (229 MB)
- **Colonnes** : user_id, session_id, timestamp, date, hour, day_of_week, event_type, product_id, transaction_id, amount, segment, product_views, product_purchases

### Issue #7 : GÃ©nÃ©rer daily_metrics.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/generate_daily_metrics.py` : MÃ©triques quotidiennes (224 lignes)
- `data/clean/daily_metrics.csv` : 139 jours, 29 colonnes (24 KB)
- **MÃ©triques incluses** :
  - Base : users, sessions, produits, Ã©vÃ©nements
  - Conversion : viewâ†’cart, viewâ†’purchase, cartâ†’purchase
  - Revenus : daily_revenue, avg_order_value, min/max_order
  - Par utilisateur : events_per_user, sessions_per_user, revenue_per_user
  - Moyennes mobiles (MA7) : revenue, users, conversion
  - Segmentation : users_new, users_occasional, users_regular, users_premium
  - Temporel : day_of_week, week_number, month, is_weekend

### Issue #8 : GÃ©nÃ©rer products_summary.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/generate_products_summary.py` : Analyse produits (268 lignes)
- `data/clean/products_summary.csv` : 235K produits, 21 colonnes (20 MB)
- **MÃ©triques incluses** :
  - Rang et catÃ©gorisation (Top Performer, High Revenue)
  - Engagement : views, add_to_carts, purchases, unique_users
  - Conversion : viewâ†’cart, viewâ†’purchase, cartâ†’purchase
  - Revenus : total_revenue, avg_price, min/max_price
  - Performance : events_per_user, revenue_per_user, revenue_per_view

---

## ğŸ“Š KPIs Globaux

### Utilisateurs

- **Total** : 1,407,580 utilisateurs uniques
- **Sessions** : 1,649,534 (1.17 sessions/user en moyenne)
- **Segmentation** :
  - New : 70% (983K users)
  - Occasional : 17% (239K users)
  - Regular : 7% (99K users)
  - Premium : 6% (89K users)

### Ã‰vÃ©nements

- **Total** : 2,755,641 Ã©vÃ©nements
- **Par type** :
  - Views : 2,664,218 (96.7%)
  - Add-to-carts : 68,966 (2.5%)
  - Transactions : 22,457 (0.8%)
- **Moyenne** : 1.96 Ã©vÃ©nements/utilisateur

### Conversion

- **View â†’ Add-to-cart** : 2.59%
- **View â†’ Purchase** : 0.84%
- **Cart â†’ Purchase** : 32.56%

### Revenus

- **Total** : 5,732,867.82 â‚¬
- **Par jour** : 41,243.65 â‚¬ (moyenne)
- **Panier moyen** : 255.28 â‚¬
- **Par utilisateur** : 4.07 â‚¬

### Produits

- **CataloguÃ©s** : 235,061 produits
- **Avec ventes** : 12,025 (5.1%)
- **Sans ventes** : 223,036 (94.9%)
- **Revenu moyen** : 24.39 â‚¬/produit
- **Top produit #461686** : 34,781.58 â‚¬ (133 achats, 5.24% conversion)

### Meilleurs jours

- **Revenue max** : 2015-07-28
- **Utilisateurs max** : 2015-07-26
- **Conversion max** : 2015-07-28

---

## ğŸ“ Structure des donnÃ©es

```
data/
â”œâ”€â”€ raw/                          # DonnÃ©es brutes (942 MB)
â”‚   â”œâ”€â”€ events.csv
â”‚   â”œâ”€â”€ item_properties.csv
â”‚   â””â”€â”€ category_tree.csv
â”‚
â””â”€â”€ clean/                        # DonnÃ©es nettoyÃ©es et enrichies
    â”œâ”€â”€ events_cleaned.csv        # 2.7M Ã©vÃ©nements nettoyÃ©s
    â”œâ”€â”€ data_clean.csv            # 2.7M lignes consolidÃ©es (229 MB)
    â”œâ”€â”€ daily_metrics.csv         # 139 jours de mÃ©triques (24 KB)
    â”œâ”€â”€ products_summary.csv      # 235K produits analysÃ©s (20 MB)
    â”‚
    â”œâ”€â”€ events_enriched.csv       # Ã‰vÃ©nements + segments + produits (242 MB)
    â”œâ”€â”€ sessions_enriched.csv     # Sessions + segments (134 MB)
    â”œâ”€â”€ transactions_enriched.csv # Transactions enrichies (2 MB)
    â”‚
    â”œâ”€â”€ daily_funnel.csv          # Entonnoir quotidien
    â”œâ”€â”€ hourly_analysis.csv       # ActivitÃ© horaire
    â”œâ”€â”€ segment_performance.csv   # Performance par segment
    â”œâ”€â”€ user_journey.csv          # Parcours utilisateurs (105 MB)
    â””â”€â”€ product_performance.csv   # Performance produits (7.5 MB)
```

---

## ğŸ› ï¸ Scripts dÃ©veloppÃ©s

```
scripts/
â”œâ”€â”€ download_data.py                    # TÃ©lÃ©chargement Kaggle
â”œâ”€â”€ inspect_csv.py                      # Exploration donnÃ©es
â”œâ”€â”€ clean_events.py                     # Nettoyage Ã©vÃ©nements
â”œâ”€â”€ clean_item_properties.py            # Nettoyage propriÃ©tÃ©s
â”œâ”€â”€ merge_data.py                       # Fusion et enrichissement
â”œâ”€â”€ generate_data_clean_simple.py       # Consolidation donnÃ©es
â”œâ”€â”€ generate_daily_metrics.py           # MÃ©triques quotidiennes
â””â”€â”€ generate_products_summary.py        # Analyse produits
```

---

## ğŸš€ Utilisation

### PrÃ©requis

```bash
# Python 3.12+
pip install pandas numpy kaggle

# Configuration Kaggle API
export KAGGLE_USERNAME=<votre_username>
export KAGGLE_KEY=<votre_key>
```

### TÃ©lÃ©charger et prÃ©parer les donnÃ©es

```bash
# 1. TÃ©lÃ©charger le dataset
python scripts/download_data.py

# 2. Nettoyer les donnÃ©es
python scripts/clean_events.py
python scripts/clean_item_properties.py

# 3. Fusionner et enrichir
python scripts/merge_data.py

# 4. GÃ©nÃ©rer les fichiers d'analyse
python scripts/generate_data_clean_simple.py
python scripts/generate_daily_metrics.py
python scripts/generate_products_summary.py
```

---

## ğŸ“ˆ Insights clÃ©s

### 1. Conversion en entonnoir classique

- **96.7%** des interactions sont des vues
- Seulement **2.5%** ajoutent au panier
- **32.6%** des paniers se convertissent en achat
- **OpportunitÃ©** : Optimiser la transition view â†’ cart (+2.59% actuellement)

### 2. Segmentation utilisateurs

- **70% sont "New"** : OpportunitÃ© de rÃ©tention
- **Premium (6%)** reprÃ©sentent probablement une part disproportionnÃ©e du revenu
- **StratÃ©gie** : Programmes de fidÃ©lisation pour convertir New â†’ Occasional â†’ Regular

### 3. Catalogue produits

- **94.9% des produits n'ont jamais Ã©tÃ© vendus** : ProblÃ¨me de merchandising
- **5.1% des produits gÃ©nÃ¨rent 100% du revenu** : Concentration extrÃªme
- **Top 4.7% ("Top Performers")** : Focus sur ces produits pour maximiser ROI

### 4. SaisonnalitÃ©

- **Pic d'activitÃ©** : Fin juillet 2015 (Ã©tÃ©)
- **Variation hebdomadaire** : Analyse des weekends vs semaine disponible
- **Tendances** : Moyennes mobiles (MA7) pour lisser les variations

---

## ğŸ¯ Milestones du Projet

### âœ… Milestone 1 : Dataset & PrÃ©paration des DonnÃ©es

**Statut** : COMPLÃ‰TÃ‰ (8/8 issues)  
**Branche** : `feature/data-preprocessing`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… TÃ©lÃ©chargement et nettoyage des donnÃ©es RetailRocket
- âœ… 8 tables enrichies (490 MB)
- âœ… Scripts de transformation et agrÃ©gation
- âœ… MÃ©triques quotidiennes et analyse produits

---

### âœ… Milestone 2 : KPIs & MÃ©triques Business

**Statut** : COMPLÃ‰TÃ‰ (6/6 issues)  
**Branche** : `feature/kpi-metrics`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… Calcul des KPIs principaux (conversion, revenu, engagement)
- âœ… Segmentation utilisateurs (New, Occasional, Regular, Premium)
- âœ… Analyse temporelle (daily, weekly, monthly)
- âœ… Moyennes mobiles et tendances
- âœ… MÃ©triques par produit et catÃ©gorie

---

### âœ… Milestone 3 : A/B Testing & Simulations

**Statut** : COMPLÃ‰TÃ‰ (10/10 issues)  
**Branche** : `feature/ab-testing`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… 16 scÃ©narios de test A/B simulÃ©s
- âœ… Simulations Monte Carlo (10,000 itÃ©rations/scenario)
- âœ… Tests statistiques (Chi-Square, Z-Test)
- âœ… Calcul puissance statistique (78-81%)
- âœ… DonnÃ©es de simulation sur 30 jours (480 lignes)
- âœ… MÃ©triques : lift, confidence, p-value, ROI

---

### âœ… Milestone 4 : Dashboard Interactif

**Statut** : COMPLÃ‰TÃ‰ (19/19 issues)  
**Branche** : `feature/dashboard-home`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… Application Dash multi-pages (12 pages)
- âœ… Visualisations Plotly interactives (60+ graphiques)
- âœ… Filtres dynamiques (date, segment, produit)
- âœ… Page Accueil avec KPIs temps rÃ©el
- âœ… Pages d'analyse : Trafic, Comportement, Conversions
- âœ… Pages produits : Performance, Pareto, Funnel
- âœ… Pages A/B : Simulations, RÃ©sultats, Calculateur
- âœ… Page Visualisations avancÃ©es
- âœ… Page MÃ©thodologie (guide complet)
- âœ… Page Ã€ Propos (documentation)
- âœ… ThÃ¨me dark moderne avec Bootstrap 5
- âœ… Gestion d'erreurs et callbacks optimisÃ©s

**Technologies** :

- Python 3.12+
- Dash 2.14.2
- Plotly 5.18.0
- Pandas, NumPy, SciPy
- Bootstrap 5 + Font Awesome

---

### ğŸš§ Milestone 5 : Docker & DÃ©ploiement

**Statut** : EN COURS (11/14 issues complÃ©tÃ©es)  
**Branche** : `feature/docker-setup`  
**Date** : DÃ©cembre 2025

**Objectif** : Rendre l'application portable et exÃ©cutable avec Docker

#### Containerisation Dash App (Issues #28-31)

- [x] **#28** - CrÃ©er Dockerfile pour l'application Dash âœ…
- [x] **#29** - CrÃ©er docker-compose.yml multi-services âœ…
- [x] **#30** - Tester build de l'image Docker âœ…
- [x] **#31** - Tester run et accÃ¨s port 8050 âœ…

#### PostgreSQL Integration (Issues #41-43)

- [x] **#41** - CrÃ©er service Postgres dans docker-compose âœ…
- [x] **#42** - CrÃ©er script de migration/init SQL âœ…
- [x] **#43** - Importer les KPIs dans Postgres automatiquement âœ…

#### Grafana Monitoring (Issues #44-48)

- [x] **#44** - Ajouter Grafana dans docker-compose âœ…
- [x] **#45** - Configurer datasource Postgres âœ…
- [x] **#46** - CrÃ©er dashboard Grafana (JSON) âœ…
- [ ] **#47** - Panels : sessions, conversion, revenues, erreurs
- [x] **#48** - Test accÃ¨s http://localhost:3000 âœ…

#### SÃ©curitÃ© & Monitoring (Issues #50, #52-53, #55-56)

- [x] **#50** - Optimiser volumes et rÃ©seaux âœ…
- [x] **#52** - Configurer Falco pour monitoring sÃ©curitÃ© âœ…
- [x] **#53** - Ajouter Loki et Promtail pour collecte logs âœ…
- [x] **#55** - Configurer Grafana pour afficher les logs de sÃ©curitÃ© âœ…
- [x] **#56** - Ajouter alertes (connexions suspectes, shell, modifications fichiers) âœ…

#### Tests Complets (Issue #49)

- [ ] **#49** - docker-compose up â€” tests complets end-to-end

**Architecture cible** :

```
docker-compose.yml
â”œâ”€â”€ dash-app (port 8050)
â”œâ”€â”€ postgres (port 5432)
â”œâ”€â”€ grafana (port 3000)
â”œâ”€â”€ loki (logs)
â””â”€â”€ promtail (agent)
```

---

## ğŸš€ Installation & DÃ©marrage

### PrÃ©requis

```bash
# Python 3.12+
pip install -r dashboard/requirements.txt
```

### Lancer le Dashboard

```bash
# Depuis le dossier racine
cd dashboard
python app.py

# AccÃ©der au dashboard
http://127.0.0.1:8050
```

> **Note** : Les donnÃ©es sont dÃ©jÃ  nettoyÃ©es et prÃªtes Ã  l'emploi dans le dossier `data/clean/`. Aucune configuration Kaggle API n'est nÃ©cessaire pour utiliser le dashboard.

### PrÃ©paration des donnÃ©es (optionnel)

Si vous souhaitez tÃ©lÃ©charger et retraiter les donnÃ©es depuis zÃ©ro :

```bash
# 1. Configurer Kaggle API
export KAGGLE_USERNAME=votre_username
export KAGGLE_KEY=votre_key

# 2. TÃ©lÃ©charger le dataset
python scripts/download_data.py

# 3. Nettoyer et enrichir les donnÃ©es
python scripts/clean_events.py
python scripts/clean_item_properties.py
python scripts/merge_data.py
python scripts/generate_data_clean_simple.py
python scripts/generate_daily_metrics.py
python scripts/generate_products_summary.py
```

### Avec Docker (Ã  venir - Milestone 5)

```bash
# Build et run tous les services
docker-compose up --build

# Services disponibles
# - Dashboard: http://localhost:8050
# - Grafana: http://localhost:3000
# - PostgreSQL: localhost:5432
```

---

## ğŸ“¦ DÃ©pendances

```txt
dash==2.14.2
dash-bootstrap-components==1.5.0
plotly==5.18.0
pandas>=2.0.0
numpy>=1.24.0
scipy>=1.11.0
```

---

## ğŸ‘¥ Ã‰quipe & Contribution

**DÃ©veloppÃ© par** : Christh Mampassi  
**Email** : cmampassi273@gmail.com  
**Repository** : [Christh2022/ecommerce-abtest-dashboard](https://github.com/Christh2022/ecommerce-abtest-dashboard)  
**Branche main** : `main`  
**Branche dev** : `dev`

---

## ğŸ“ License

Ce projet utilise le dataset RetailRocket sous licence publique Kaggle.

---

**DerniÃ¨re mise Ã  jour** : 17 dÃ©cembre 2025  
**Version** : 1.1.0  
**Milestones complÃ©tÃ©s** : 4/5 âœ…  
**Issues rÃ©solues** : 43/57

**Changelog v1.1.0** (17 dÃ©cembre 2025) :

- âœ¨ **NOUVEAU** : Assistant vocal intelligent avec reconnaissance vocale
- ğŸ¤ SystÃ¨me de commandes vocales pour navigation mains-libres
- ğŸ—£ï¸ Explications guidÃ©es de l'application par la voix
- ğŸ”„ Interaction continue avec questions/rÃ©ponses automatiques
- ğŸ“¢ SynthÃ¨se vocale multilingue (franÃ§ais)
- ğŸ¨ AmÃ©lioration des icÃ´nes Font Awesome (v6.5.1)
- ğŸ“ Documentation enrichie avec section assistant vocal

**Changelog v1.0.1** (14 dÃ©cembre 2025) :

- âœ… Correction du problÃ¨me de numeric overflow lors de l'import des donnÃ©es
- âœ… Ajout du script `fix_numeric_overflow.py` pour corriger automatiquement le schÃ©ma
- âœ… Mise Ã  jour de la documentation avec les Ã©tapes correctes d'import
- âœ… AmÃ©lioration des instructions pour les collaborateurs

---

## ğŸ¯ Roadmap Future

### Version 1.2.0 (Ã€ venir)

- ğŸ¤– Extension des commandes vocales (20+ commandes)
- ğŸ“Š Navigation vocale vers toutes les pages du dashboard
- ğŸ¨ Visualisation rÃ©active aux commandes vocales
- ğŸŒ Support multilingue (anglais, espagnol)

### Version 2.0.0 (Q1 2026)

- ğŸ§  IntÃ©gration d'IA pour analyses prÃ©dictives
- ğŸ“ˆ Recommandations automatiques basÃ©es sur les KPIs
- ğŸ”” Alertes vocales en temps rÃ©el
- ğŸ“± Application mobile avec assistant vocal
