# E-commerce Dashboard & A/B Testing ğŸš€

Plateforme d'analyse e-commerce avec dashboard interactif et outils d'A/B testing utilisant Python, Dash, PostgreSQL, Docker et Grafana.

## ğŸ“Š Vue d'ensemble

Ce projet analyse les donnÃ©es du dataset **RetailRocket** (2.7M Ã©vÃ©nements, 1.4M utilisateurs, 235K produits) pour crÃ©er un dashboard de visualisation et des outils d'analyse de performance e-commerce.

### Objectifs

- ğŸ“ˆ **Dashboard interactif** : 12+ pages de visualisation en temps rÃ©el des KPIs e-commerce
- ğŸ§ª **A/B Testing** : 16 scÃ©narios de test simulÃ©s avec analyse statistique complÃ¨te
- ğŸ“‰ **Analyse de tendances** : MÃ©triques quotidiennes, entonnoirs de conversion, performance produits
- ğŸ¯ **MÃ©thodologie** : Guide complet des bonnes pratiques en A/B testing
- ğŸ³ **DÃ©ploiement** : Application containerisÃ©e avec Docker, PostgreSQL et Grafana

---

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis

- [Docker Desktop](https://www.docker.com/products/docker-desktop) installÃ© et en cours d'exÃ©cution
- [Git](https://git-scm.com/downloads) installÃ©
- Au moins 4 GB de RAM disponible
- 5 GB d'espace disque libre

### Installation

1. **Cloner le projet**
   ```bash
   git clone https://github.com/votre-username/ecommerce-abtest-dashboard.git
   cd ecommerce-abtest-dashboard
   ```

2. **Lancer tous les services**
   ```bash
   docker compose -f docker-compose.secure.yml up -d
   ```
   
   Cette commande va :
   - âœ… Construire les images Docker
   - âœ… DÃ©marrer PostgreSQL avec les donnÃ©es prÃ©-chargÃ©es
   - âœ… Lancer l'application Dash (Dashboard)
   - âœ… DÃ©marrer Grafana, Prometheus, Loki (Monitoring)
   - âœ… CrÃ©er automatiquement les 11 dashboards Grafana

3. **Attendre le dÃ©marrage complet** (~2-3 minutes)
   ```bash
   # VÃ©rifier l'Ã©tat des services
   docker compose -f docker-compose.secure.yml ps
   ```

### AccÃ¨s aux Services

Une fois les conteneurs dÃ©marrÃ©s, accÃ©dez aux diffÃ©rentes interfaces :

| Service | URL | Identifiants | Description |
|---------|-----|--------------|-------------|
| ğŸ¨ **Dashboard Dash** | http://localhost:8050 | - | Application principale d'analyse |
| ğŸ“Š **Grafana** | http://localhost:3000 | admin / admin123 | 11 dashboards de monitoring |
| ğŸ” **Prometheus** | http://localhost:9090 | - | MÃ©triques temps rÃ©el |
| ğŸ—„ï¸ **PostgreSQL** | localhost:5432 | dashuser / dashpass | Base de donnÃ©es (ecommerce_db) |

### ArrÃªter le Projet

```bash
# ArrÃªter tous les services
docker compose -f docker-compose.secure.yml down

# ArrÃªter et supprimer les volumes (âš ï¸ efface les donnÃ©es)
docker compose -f docker-compose.secure.yml down -v
```

### Relancer le Projet

```bash
# RedÃ©marrer les services existants
docker compose -f docker-compose.secure.yml up -d

# Reconstruire les images (aprÃ¨s modification du code)
docker compose -f docker-compose.secure.yml up -d --build
```

### Charger les DonnÃ©es dans PostgreSQL

Les donnÃ©es CSV doivent Ãªtre importÃ©es dans PostgreSQL aprÃ¨s le dÃ©marrage :

```bash
# Option 1 : Importer depuis l'hÃ´te (nÃ©cessite psycopg2)
python scripts/import_data_to_postgres.py

# Option 2 : Importer via Docker (recommandÃ© sur Windows)
docker exec -i ecommerce-postgres psql -U dashuser -d ecommerce_db << EOF
\copy daily_metrics FROM '/docker-entrypoint-initdb.d/daily_metrics.csv' WITH CSV HEADER;
EOF

# Option 3 : Utiliser le script de migration complet
docker exec ecommerce-postgres psql -U dashuser -d ecommerce_db -f /docker-entrypoint-initdb.d/01_init.sql
```

**VÃ©rifier l'import** :
```bash
# VÃ©rifier le nombre de lignes dans les tables
docker exec ecommerce-postgres psql -U dashuser -d ecommerce_db -c "SELECT 'daily_metrics' as table, COUNT(*) FROM daily_metrics UNION ALL SELECT 'products_summary', COUNT(*) FROM products_summary;"
```

### CrÃ©er les Dashboards Grafana (Optionnel)

Les dashboards Grafana doivent Ãªtre crÃ©Ã©s manuellement aprÃ¨s le chargement des donnÃ©es :

```bash
# Attendre que tous les services soient dÃ©marrÃ©s (~2 minutes)
# Puis exÃ©cuter les scripts de crÃ©ation des dashboards :

# 1. Dashboards de base (Funnel, Segmentation, Produits)
python create_dashboards_1_3.py

# 2. Dashboards avancÃ©s (Cohortes, Real-Time, PrÃ©dictif)
python create_dashboards_4_6.py

# 3. Dashboard Business Intelligence
python create_bi_dashboard.py

# 4. Dashboard E-Commerce complet
python create_full_dashboard.py

# 5. Dashboard Monitoring
python create_monitoring_dashboard.py

# 6. Dashboard Prometheus
python create_prometheus_dashboard.py
```

**Note** : Les dashboards sont crÃ©Ã©s via l'API Grafana. Assurez-vous que Grafana est dÃ©marrÃ© et accessible sur http://localhost:3000 avant d'exÃ©cuter ces scripts.

---

## âœ¨ DÃ©mo en Ligne

**Dashboard accessible Ã ** : http://localhost:8050

**Pages disponibles** :

- ğŸ  Accueil - Vue d'ensemble et KPIs
- ğŸ‘¥ Trafic - Analyse des visiteurs
- ğŸ–±ï¸ Comportement - Patterns d'engagement
- ğŸ›’ Conversions - Funnel analysis
- ğŸ“¦ Produits - Performance et Pareto
- ğŸ”„ Funnel - Visualisation tunnel
- ğŸ§ª Simulations A/B - 16 scÃ©narios
- ğŸ“Š RÃ©sultats A/B - Analyse statistique
- ğŸ§® Calculateur Z-Test - Outil interactif
- ğŸ“ˆ Visualisations - Graphiques avancÃ©s
- ğŸ“š MÃ©thodologie - Guide complet
- â„¹ï¸ Ã€ Propos - Documentation projet

**Grafana Dashboards** : http://localhost:3000 (admin/admin123)

AprÃ¨s avoir exÃ©cutÃ© les scripts ci-dessus, vous aurez accÃ¨s Ã  10 dashboards :
- Business Intelligence & Decision Support
- Cohort Analysis & Retention
- Customer Journey & Funnel Analysis
- Customer Segmentation Analysis
- E-Commerce A/B Test Analytics
- E-Commerce Dashboard (Prometheus)
- E-Commerce Monitoring Dashboard
- Predictive Analytics & Forecasting
- Product Performance Analysis
- Real-Time Performance Monitoring

---

## ğŸ¯ Milestone 1 : Dataset & PrÃ©paration des DonnÃ©es âœ…

**Statut** : COMPLÃ‰TÃ‰ (8 issues)  
**Branche** : `feature/data-preprocessing`  
**PÃ©riode** : DÃ©cembre 2025

### ğŸ“¦ Dataset RetailRocket

Source : [Kaggle - RetailRocket E-commerce Dataset](https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset)

**CaractÃ©ristiques :**

- **PÃ©riode couverte** : 2015-05-03 â†’ 2015-09-18 (137 jours / 19.6 semaines)
- **Ã‰vÃ©nements totaux** : 2,755,641 (aprÃ¨s nettoyage)
  - Views : 2,664,218 (96.7%)
  - Add-to-carts : 68,966 (2.5%)
  - Transactions : 22,457 (0.8%)
- **Utilisateurs uniques** : 1,407,580
- **Sessions uniques** : 1,649,534
- **Produits uniques** : 235,061
- **Revenu total** : 5,732,867.82 â‚¬
- **Taux de conversion global** : 0.84%

---

## ğŸ”§ Issues ComplÃ©tÃ©es

### Issue #1 : TÃ©lÃ©charger le dataset RetailRocket âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/download_data.py` : Script de tÃ©lÃ©chargement via Kaggle API
- DonnÃ©es brutes (942 MB) â†’ nettoyÃ©es (536 MB)

### Issue #2 : Inspecter les fichiers CSV âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/inspect_csv.py` : Analyse exploratoire des donnÃ©es
- RÃ©sultats : 460 doublons dÃ©tectÃ©s dans `events.csv`

### Issue #3 : Nettoyer events.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/clean_events.py` : Suppression des doublons
- `data/clean/events_cleaned.csv` : 2,755,641 lignes (460 doublons supprimÃ©s)

### Issue #4 : Nettoyer item_properties.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/clean_item_properties.py` : Parsing et structuration
- `data/clean/item_properties_cleaned.csv` : 20,275,902 lignes, 9 colonnes typÃ©es

### Issue #5 : Fusionner les donnÃ©es âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/merge_data.py` : Fusion et enrichissement (515 lignes)
- **8 tables enrichies** (490 MB total) :
  - `events_enriched.csv` : 2.7M lignes, 12 colonnes (242 MB)
  - `sessions_enriched.csv` : 1.6M lignes, 10 colonnes (134 MB)
  - `transactions_enriched.csv` : 22K lignes, 13 colonnes (2 MB)
  - `daily_funnel.csv` : 139 jours, entonnoir de conversion
  - `hourly_analysis.csv` : 24 heures, activitÃ© horaire
  - `segment_performance.csv` : 4 segments utilisateurs
  - `user_journey.csv` : 1.4M parcours (105 MB)
  - `product_performance.csv` : 235K produits (7.5 MB)

### Issue #6 : GÃ©nÃ©rer data_clean.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/generate_data_clean_simple.py` : Consolidation optimisÃ©e par chunks
- `data/clean/data_clean.csv` : 2.7M lignes, 13 colonnes (229 MB)
- **Colonnes** : user_id, session_id, timestamp, date, hour, day_of_week, event_type, product_id, transaction_id, amount, segment, product_views, product_purchases

### Issue #7 : GÃ©nÃ©rer daily_metrics.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/generate_daily_metrics.py` : MÃ©triques quotidiennes (224 lignes)
- `data/clean/daily_metrics.csv` : 139 jours, 29 colonnes (24 KB)
- **MÃ©triques incluses** :
  - Base : users, sessions, produits, Ã©vÃ©nements
  - Conversion : viewâ†’cart, viewâ†’purchase, cartâ†’purchase
  - Revenus : daily_revenue, avg_order_value, min/max_order
  - Par utilisateur : events_per_user, sessions_per_user, revenue_per_user
  - Moyennes mobiles (MA7) : revenue, users, conversion
  - Segmentation : users_new, users_occasional, users_regular, users_premium
  - Temporel : day_of_week, week_number, month, is_weekend

### Issue #8 : GÃ©nÃ©rer products_summary.csv âœ…

**Fichiers crÃ©Ã©s :**

- `scripts/generate_products_summary.py` : Analyse produits (268 lignes)
- `data/clean/products_summary.csv` : 235K produits, 21 colonnes (20 MB)
- **MÃ©triques incluses** :
  - Rang et catÃ©gorisation (Top Performer, High Revenue)
  - Engagement : views, add_to_carts, purchases, unique_users
  - Conversion : viewâ†’cart, viewâ†’purchase, cartâ†’purchase
  - Revenus : total_revenue, avg_price, min/max_price
  - Performance : events_per_user, revenue_per_user, revenue_per_view

---

## ğŸ“Š KPIs Globaux

### Utilisateurs

- **Total** : 1,407,580 utilisateurs uniques
- **Sessions** : 1,649,534 (1.17 sessions/user en moyenne)
- **Segmentation** :
  - New : 70% (983K users)
  - Occasional : 17% (239K users)
  - Regular : 7% (99K users)
  - Premium : 6% (89K users)

### Ã‰vÃ©nements

- **Total** : 2,755,641 Ã©vÃ©nements
- **Par type** :
  - Views : 2,664,218 (96.7%)
  - Add-to-carts : 68,966 (2.5%)
  - Transactions : 22,457 (0.8%)
- **Moyenne** : 1.96 Ã©vÃ©nements/utilisateur

### Conversion

- **View â†’ Add-to-cart** : 2.59%
- **View â†’ Purchase** : 0.84%
- **Cart â†’ Purchase** : 32.56%

### Revenus

- **Total** : 5,732,867.82 â‚¬
- **Par jour** : 41,243.65 â‚¬ (moyenne)
- **Panier moyen** : 255.28 â‚¬
- **Par utilisateur** : 4.07 â‚¬

### Produits

- **CataloguÃ©s** : 235,061 produits
- **Avec ventes** : 12,025 (5.1%)
- **Sans ventes** : 223,036 (94.9%)
- **Revenu moyen** : 24.39 â‚¬/produit
- **Top produit #461686** : 34,781.58 â‚¬ (133 achats, 5.24% conversion)

### Meilleurs jours

- **Revenue max** : 2015-07-28
- **Utilisateurs max** : 2015-07-26
- **Conversion max** : 2015-07-28

---

## ğŸ“ Structure des donnÃ©es

```
data/
â”œâ”€â”€ raw/                          # DonnÃ©es brutes (942 MB)
â”‚   â”œâ”€â”€ events.csv
â”‚   â”œâ”€â”€ item_properties.csv
â”‚   â””â”€â”€ category_tree.csv
â”‚
â””â”€â”€ clean/                        # DonnÃ©es nettoyÃ©es et enrichies
    â”œâ”€â”€ events_cleaned.csv        # 2.7M Ã©vÃ©nements nettoyÃ©s
    â”œâ”€â”€ data_clean.csv            # 2.7M lignes consolidÃ©es (229 MB)
    â”œâ”€â”€ daily_metrics.csv         # 139 jours de mÃ©triques (24 KB)
    â”œâ”€â”€ products_summary.csv      # 235K produits analysÃ©s (20 MB)
    â”‚
    â”œâ”€â”€ events_enriched.csv       # Ã‰vÃ©nements + segments + produits (242 MB)
    â”œâ”€â”€ sessions_enriched.csv     # Sessions + segments (134 MB)
    â”œâ”€â”€ transactions_enriched.csv # Transactions enrichies (2 MB)
    â”‚
    â”œâ”€â”€ daily_funnel.csv          # Entonnoir quotidien
    â”œâ”€â”€ hourly_analysis.csv       # ActivitÃ© horaire
    â”œâ”€â”€ segment_performance.csv   # Performance par segment
    â”œâ”€â”€ user_journey.csv          # Parcours utilisateurs (105 MB)
    â””â”€â”€ product_performance.csv   # Performance produits (7.5 MB)
```

---

## ğŸ› ï¸ Scripts dÃ©veloppÃ©s

```
scripts/
â”œâ”€â”€ download_data.py                    # TÃ©lÃ©chargement Kaggle
â”œâ”€â”€ inspect_csv.py                      # Exploration donnÃ©es
â”œâ”€â”€ clean_events.py                     # Nettoyage Ã©vÃ©nements
â”œâ”€â”€ clean_item_properties.py            # Nettoyage propriÃ©tÃ©s
â”œâ”€â”€ merge_data.py                       # Fusion et enrichissement
â”œâ”€â”€ generate_data_clean_simple.py       # Consolidation donnÃ©es
â”œâ”€â”€ generate_daily_metrics.py           # MÃ©triques quotidiennes
â””â”€â”€ generate_products_summary.py        # Analyse produits
```

---

## ğŸš€ Utilisation

### PrÃ©requis

```bash
# Python 3.12+
pip install pandas numpy kaggle

# Configuration Kaggle API
export KAGGLE_USERNAME=<votre_username>
export KAGGLE_KEY=<votre_key>
```

### TÃ©lÃ©charger et prÃ©parer les donnÃ©es

```bash
# 1. TÃ©lÃ©charger le dataset
python scripts/download_data.py

# 2. Nettoyer les donnÃ©es
python scripts/clean_events.py
python scripts/clean_item_properties.py

# 3. Fusionner et enrichir
python scripts/merge_data.py

# 4. GÃ©nÃ©rer les fichiers d'analyse
python scripts/generate_data_clean_simple.py
python scripts/generate_daily_metrics.py
python scripts/generate_products_summary.py
```

---

## ğŸ“ˆ Insights clÃ©s

### 1. Conversion en entonnoir classique

- **96.7%** des interactions sont des vues
- Seulement **2.5%** ajoutent au panier
- **32.6%** des paniers se convertissent en achat
- **OpportunitÃ©** : Optimiser la transition view â†’ cart (+2.59% actuellement)

### 2. Segmentation utilisateurs

- **70% sont "New"** : OpportunitÃ© de rÃ©tention
- **Premium (6%)** reprÃ©sentent probablement une part disproportionnÃ©e du revenu
- **StratÃ©gie** : Programmes de fidÃ©lisation pour convertir New â†’ Occasional â†’ Regular

### 3. Catalogue produits

- **94.9% des produits n'ont jamais Ã©tÃ© vendus** : ProblÃ¨me de merchandising
- **5.1% des produits gÃ©nÃ¨rent 100% du revenu** : Concentration extrÃªme
- **Top 4.7% ("Top Performers")** : Focus sur ces produits pour maximiser ROI

### 4. SaisonnalitÃ©

- **Pic d'activitÃ©** : Fin juillet 2015 (Ã©tÃ©)
- **Variation hebdomadaire** : Analyse des weekends vs semaine disponible
- **Tendances** : Moyennes mobiles (MA7) pour lisser les variations

---

## ğŸ¯ Milestones du Projet

### âœ… Milestone 1 : Dataset & PrÃ©paration des DonnÃ©es

**Statut** : COMPLÃ‰TÃ‰ (8/8 issues)  
**Branche** : `feature/data-preprocessing`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… TÃ©lÃ©chargement et nettoyage des donnÃ©es RetailRocket
- âœ… 8 tables enrichies (490 MB)
- âœ… Scripts de transformation et agrÃ©gation
- âœ… MÃ©triques quotidiennes et analyse produits

---

### âœ… Milestone 2 : KPIs & MÃ©triques Business

**Statut** : COMPLÃ‰TÃ‰ (6/6 issues)  
**Branche** : `feature/kpi-metrics`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… Calcul des KPIs principaux (conversion, revenu, engagement)
- âœ… Segmentation utilisateurs (New, Occasional, Regular, Premium)
- âœ… Analyse temporelle (daily, weekly, monthly)
- âœ… Moyennes mobiles et tendances
- âœ… MÃ©triques par produit et catÃ©gorie

---

### âœ… Milestone 3 : A/B Testing & Simulations

**Statut** : COMPLÃ‰TÃ‰ (10/10 issues)  
**Branche** : `feature/ab-testing`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… 16 scÃ©narios de test A/B simulÃ©s
- âœ… Simulations Monte Carlo (10,000 itÃ©rations/scenario)
- âœ… Tests statistiques (Chi-Square, Z-Test)
- âœ… Calcul puissance statistique (78-81%)
- âœ… DonnÃ©es de simulation sur 30 jours (480 lignes)
- âœ… MÃ©triques : lift, confidence, p-value, ROI

---

### âœ… Milestone 4 : Dashboard Interactif

**Statut** : COMPLÃ‰TÃ‰ (19/19 issues)  
**Branche** : `feature/dashboard-home`  
**Date** : DÃ©cembre 2025

**Livrables** :

- âœ… Application Dash multi-pages (12 pages)
- âœ… Visualisations Plotly interactives (60+ graphiques)
- âœ… Filtres dynamiques (date, segment, produit)
- âœ… Page Accueil avec KPIs temps rÃ©el
- âœ… Pages d'analyse : Trafic, Comportement, Conversions
- âœ… Pages produits : Performance, Pareto, Funnel
- âœ… Pages A/B : Simulations, RÃ©sultats, Calculateur
- âœ… Page Visualisations avancÃ©es
- âœ… Page MÃ©thodologie (guide complet)
- âœ… Page Ã€ Propos (documentation)
- âœ… ThÃ¨me dark moderne avec Bootstrap 5
- âœ… Gestion d'erreurs et callbacks optimisÃ©s

**Technologies** :

- Python 3.12+
- Dash 2.14.2
- Plotly 5.18.0
- Pandas, NumPy, SciPy
- Bootstrap 5 + Font Awesome

---

### ğŸš§ Milestone 5 : Docker & DÃ©ploiement

**Statut** : EN COURS (11/14 issues complÃ©tÃ©es)  
**Branche** : `feature/docker-setup`  
**Date** : DÃ©cembre 2025

**Objectif** : Rendre l'application portable et exÃ©cutable avec Docker

#### Containerisation Dash App (Issues #28-31)

- [x] **#28** - CrÃ©er Dockerfile pour l'application Dash âœ…
- [x] **#29** - CrÃ©er docker-compose.yml multi-services âœ…
- [x] **#30** - Tester build de l'image Docker âœ…
- [x] **#31** - Tester run et accÃ¨s port 8050 âœ…

#### PostgreSQL Integration (Issues #41-43)

- [x] **#41** - CrÃ©er service Postgres dans docker-compose âœ…
- [x] **#42** - CrÃ©er script de migration/init SQL âœ…
- [x] **#43** - Importer les KPIs dans Postgres automatiquement âœ…

#### Grafana Monitoring (Issues #44-48)

- [x] **#44** - Ajouter Grafana dans docker-compose âœ…
- [x] **#45** - Configurer datasource Postgres âœ…
- [x] **#46** - CrÃ©er dashboard Grafana (JSON) âœ…
- [ ] **#47** - Panels : sessions, conversion, revenues, erreurs
- [x] **#48** - Test accÃ¨s http://localhost:3000 âœ…

#### SÃ©curitÃ© & Monitoring (Issues #50, #52-53, #55-56)

- [x] **#50** - Optimiser volumes et rÃ©seaux âœ…
- [x] **#52** - Configurer Falco pour monitoring sÃ©curitÃ© âœ…
- [x] **#53** - Ajouter Loki et Promtail pour collecte logs âœ…
- [x] **#55** - Configurer Grafana pour afficher les logs de sÃ©curitÃ© âœ…
- [x] **#56** - Ajouter alertes (connexions suspectes, shell, modifications fichiers) âœ…

#### Tests Complets (Issue #49)

- [ ] **#49** - docker-compose up â€” tests complets end-to-end

**Architecture cible** :

```
docker-compose.yml
â”œâ”€â”€ dash-app (port 8050)
â”œâ”€â”€ postgres (port 5432)
â”œâ”€â”€ grafana (port 3000)
â”œâ”€â”€ loki (logs)
â””â”€â”€ promtail (agent)
```

---

## ğŸš€ Installation & DÃ©marrage

### PrÃ©requis

```bash
# Python 3.12+
pip install -r dashboard/requirements.txt
```

### Lancer le Dashboard

```bash
# Depuis le dossier racine
cd dashboard
python app.py

# AccÃ©der au dashboard
http://127.0.0.1:8050
```

> **Note** : Les donnÃ©es sont dÃ©jÃ  nettoyÃ©es et prÃªtes Ã  l'emploi dans le dossier `data/clean/`. Aucune configuration Kaggle API n'est nÃ©cessaire pour utiliser le dashboard.

### PrÃ©paration des donnÃ©es (optionnel)

Si vous souhaitez tÃ©lÃ©charger et retraiter les donnÃ©es depuis zÃ©ro :

```bash
# 1. Configurer Kaggle API
export KAGGLE_USERNAME=votre_username
export KAGGLE_KEY=votre_key

# 2. TÃ©lÃ©charger le dataset
python scripts/download_data.py

# 3. Nettoyer et enrichir les donnÃ©es
python scripts/clean_events.py
python scripts/clean_item_properties.py
python scripts/merge_data.py
python scripts/generate_data_clean_simple.py
python scripts/generate_daily_metrics.py
python scripts/generate_products_summary.py
```

### Avec Docker (Ã  venir - Milestone 5)

```bash
# Build et run tous les services
docker-compose up --build

# Services disponibles
# - Dashboard: http://localhost:8050
# - Grafana: http://localhost:3000
# - PostgreSQL: localhost:5432
```

---

## ğŸ“¦ DÃ©pendances

```txt
dash==2.14.2
dash-bootstrap-components==1.5.0
plotly==5.18.0
pandas>=2.0.0
numpy>=1.24.0
scipy>=1.11.0
```

---

## ğŸ‘¥ Ã‰quipe & Contribution

**DÃ©veloppÃ© par** : Christh Mampassi  
**Email** : cmampassi273@gmail.com  
**Repository** : [Christh2022/ecommerce-abtest-dashboard](https://github.com/Christh2022/ecommerce-abtest-dashboard)  
**Branche main** : `main`  
**Branche dev** : `dev`

---

## ğŸ“ License

Ce projet utilise le dataset RetailRocket sous licence publique Kaggle.

---

**DerniÃ¨re mise Ã  jour** : 11 dÃ©cembre 2025  
**Version** : 1.0.0  
**Milestones complÃ©tÃ©s** : 4/5 âœ…  
**Issues rÃ©solues** : 43/57
