# ğŸ§¹ Issue #3 - Nettoyage de events.csv

**Date:** 2025-12-08  
**Branche:** feature/data-preprocessing  
**Statut:** âœ… TerminÃ©

## ğŸ“‹ Objectif

Nettoyer le fichier `events.csv` en supprimant les doublons identifiÃ©s lors de l'inspection (Issue #2) et en validant l'intÃ©gritÃ© des donnÃ©es.

---

## ğŸ” ProblÃ¨mes IdentifiÃ©s (Issue #2)

Lors de l'inspection, nous avons dÃ©tectÃ© :
- **460 doublons** (0.02% des donnÃ©es) - lignes complÃ¨tement identiques
- **471 doublons partiels** - mÃªme timestamp + visitorid + itemid

---

## ğŸ› ï¸ OpÃ©rations de Nettoyage RÃ©alisÃ©es

### 1. Suppression des Doublons

**MÃ©thode :** Suppression des lignes complÃ¨tement identiques (toutes colonnes)

**RÃ©sultats :**
- Lignes avant : 2,756,101
- Doublons supprimÃ©s : 460
- Lignes aprÃ¨s : 2,755,641
- Taux de doublons : **0.0167%**

**Impact :**
- âœ… 0 doublon restant
- âœ… IntÃ©gritÃ© temporelle prÃ©servÃ©e (ordre chronologique maintenu)

### 2. Validation des DonnÃ©es

**VÃ©rifications effectuÃ©es :**

âœ… **Timestamps**
- Aucun timestamp invalide (<= 0)
- PÃ©riode : 2015-05-03 â†’ 2015-09-18 (137 jours)
- Format : UNIX timestamp en millisecondes

âœ… **IDs (visitorid, itemid)**
- Aucun ID nÃ©gatif ou nul
- visitorid : 1,407,580 utilisateurs uniques
- itemid : 235,061 produits uniques

âœ… **Types d'Ã©vÃ©nements**
- Uniquement 3 types valides : `view`, `addtocart`, `transaction`
- Aucun type d'Ã©vÃ©nement invalide dÃ©tectÃ©

âœ… **Transactions**
- 22,457 transactions
- Toutes les transactions ont un `transactionid` valide
- Aucune transaction sans ID

âœ… **Valeurs manquantes**
- Aucune valeur manquante dans les colonnes critiques :
  - timestamp âœ…
  - visitorid âœ…
  - event âœ…
  - itemid âœ…
- transactionid : 99.19% manquantes (normal, seules les transactions ont un ID)

### 3. Tri des DonnÃ©es

Les donnÃ©es ont Ã©tÃ© triÃ©es par **timestamp** (ordre chronologique) pour faciliter :
- L'analyse temporelle
- Le traÃ§age des sessions utilisateurs
- Le calcul des sÃ©quences d'Ã©vÃ©nements

---

## ğŸ“Š Distribution des Ã‰vÃ©nements NettoyÃ©s

### Avant Nettoyage
| Ã‰vÃ©nement    | Nombre     | Pourcentage |
|--------------|------------|-------------|
| view         | 2,664,312  | 96.67%      |
| addtocart    | 69,332     | 2.52%       |
| transaction  | 22,457     | 0.81%       |
| **TOTAL**    | **2,756,101** | **100%** |

### AprÃ¨s Nettoyage
| Ã‰vÃ©nement    | Nombre     | Pourcentage | Changement |
|--------------|------------|-------------|------------|
| view         | 2,664,218  | 96.68%      | -94 lignes |
| addtocart    | 68,966     | 2.50%       | -366 lignes |
| transaction  | 22,457     | 0.81%       | âœ… Aucun changement |
| **TOTAL**    | **2,755,641** | **100%** | **-460 lignes** |

**Observations :**
- Les transactions sont intactes âœ… (aucune transaction n'Ã©tait dupliquÃ©e)
- La plupart des doublons concernaient des `view` et `addtocart`
- Distribution globale inchangÃ©e (< 0.02% d'impact)

---

## ğŸ“ Fichiers GÃ©nÃ©rÃ©s

### 1. events_cleaned.csv

**Chemin :** `data/clean/events_cleaned.csv`

**CaractÃ©ristiques :**
- 2,755,641 lignes Ã— 5 colonnes
- Taille : 92.53 MB (vs 223.90 MB en mÃ©moire)
- TriÃ© par ordre chronologique
- 0 doublon
- 0 valeur manquante critique

**Colonnes :**
- `timestamp` (int64) : UNIX timestamp en millisecondes
- `visitorid` (int64) : ID utilisateur unique
- `event` (object) : Type d'Ã©vÃ©nement (view/addtocart/transaction)
- `itemid` (int64) : ID produit
- `transactionid` (float64) : ID transaction (vide sauf pour events = transaction)

### 2. CLEANING_REPORT.txt

**Chemin :** `data/clean/CLEANING_REPORT.txt`

**Contenu :**
- RÃ©sumÃ© des opÃ©rations
- Nombre de lignes supprimÃ©es
- Validation finale
- Distribution des Ã©vÃ©nements

---

## ğŸ”§ Script de Nettoyage

### clean_events.py

**Chemin :** `scripts/clean_events.py`

**FonctionnalitÃ©s :**

1. **Chargement sÃ©curisÃ©**
   - VÃ©rification de l'existence du fichier
   - Gestion des erreurs de lecture
   - Affichage des mÃ©tadonnÃ©es

2. **Analyse prÃ©-nettoyage**
   - DÃ©tection des doublons
   - DÃ©tection des valeurs manquantes
   - Validation des types de donnÃ©es
   - Distribution des Ã©vÃ©nements

3. **Nettoyage automatisÃ©**
   - Suppression des doublons exacts
   - Suppression des donnÃ©es invalides (timestamps nÃ©gatifs, IDs invalides)
   - Validation des transactions
   - Tri chronologique

4. **Analyse post-nettoyage**
   - Validation finale (0 doublon, 0 valeur manquante critique)
   - Comparaison avant/aprÃ¨s
   - Statistiques descriptives

5. **Sauvegarde et rapport**
   - Export CSV nettoyÃ©
   - GÃ©nÃ©ration de rapport texte
   - Recommandations pour la suite

**Usage :**
```bash
python scripts/clean_events.py
```

**Sorties :**
- `data/clean/events_cleaned.csv` : DonnÃ©es nettoyÃ©es
- `data/clean/CLEANING_REPORT.txt` : Rapport dÃ©taillÃ©

---

## ğŸ“ˆ Statistiques Comparatives

### Avant vs AprÃ¨s Nettoyage

| MÃ©trique                          | Avant        | AprÃ¨s        | Changement |
|-----------------------------------|--------------|--------------|------------|
| **Lignes totales**                | 2,756,101    | 2,755,641    | -460 (-0.0167%) |
| **Doublons**                      | 460          | 0            | âœ… -100% |
| **Valeurs manquantes critiques**  | 0            | 0            | âœ… OK |
| **Timestamps invalides**          | 0            | 0            | âœ… OK |
| **IDs invalides**                 | 0            | 0            | âœ… OK |
| **Types Ã©vÃ©nements invalides**    | 0            | 0            | âœ… OK |
| **Transactions sans ID**          | 0            | 0            | âœ… OK |
| **Taille fichier**                | ~224 MB      | 92.53 MB     | -58.7% (compression) |

### IntÃ©gritÃ© des DonnÃ©es

âœ… **100% des transactions prÃ©servÃ©es** (22,457 â†’ 22,457)  
âœ… **0 doublon restant**  
âœ… **0 donnÃ©e invalide**  
âœ… **Ordre chronologique garanti**  
âœ… **Tous les utilisateurs prÃ©servÃ©s** (1,407,580)  
âœ… **Tous les produits prÃ©servÃ©s** (235,061)

---

## ğŸ” Analyse des Doublons SupprimÃ©s

### RÃ©partition par Type d'Ã‰vÃ©nement

| Type        | Doublons SupprimÃ©s | % du Type |
|-------------|-------------------|-----------|
| view        | 94                | 0.0035%   |
| addtocart   | 366               | 0.528%    |
| transaction | 0                 | 0%        |
| **TOTAL**   | **460**           | **0.0167%** |

**Insights :**
- Les doublons affectaient principalement les `addtocart` (79.6% des doublons)
- Aucune transaction n'Ã©tait dupliquÃ©e âœ…
- Impact nÃ©gligeable sur les vues (0.0035%)

### HypothÃ¨ses sur la Cause des Doublons

1. **Double-clic utilisateur** : Clics rÃ©pÃ©tÃ©s rapides sur "Ajouter au panier"
2. **ProblÃ¨mes rÃ©seau** : Retry automatique cÃ´tÃ© client
3. **Bug de tracking** : Ã‰vÃ©nements envoyÃ©s deux fois par le SDK analytics
4. **Latence API** : Ã‰vÃ©nements enregistrÃ©s en doublon cÃ´tÃ© serveur

---

## âœ… Validation de la QualitÃ©

### Tests EffectuÃ©s

1. âœ… **Absence de doublons**
   ```python
   assert df_cleaned.duplicated().sum() == 0
   ```

2. âœ… **Absence de valeurs manquantes critiques**
   ```python
   critical_cols = ['timestamp', 'visitorid', 'event', 'itemid']
   assert df_cleaned[critical_cols].isnull().sum().sum() == 0
   ```

3. âœ… **Timestamps valides**
   ```python
   assert (df_cleaned['timestamp'] > 0).all()
   ```

4. âœ… **IDs valides**
   ```python
   assert (df_cleaned['visitorid'] >= 0).all()
   assert (df_cleaned['itemid'] >= 0).all()
   ```

5. âœ… **Types d'Ã©vÃ©nements valides**
   ```python
   valid_events = ['view', 'addtocart', 'transaction']
   assert df_cleaned['event'].isin(valid_events).all()
   ```

6. âœ… **Transactions avec ID**
   ```python
   transactions = df_cleaned[df_cleaned['event'] == 'transaction']
   assert transactions['transactionid'].notna().all()
   ```

7. âœ… **Ordre chronologique**
   ```python
   assert df_cleaned['timestamp'].is_monotonic_increasing
   ```

---

## ğŸ”„ Impact sur les Scripts Existants

### Scripts Ã  Mettre Ã  Jour

Les scripts suivants peuvent maintenant utiliser `events_cleaned.csv` au lieu de `events.csv` :

1. ~~`preprocess_retailrocket.py`~~ *(optionnel, dÃ©jÃ  exÃ©cutÃ©)*
   - Peut Ãªtre rÃ©exÃ©cutÃ© avec le fichier nettoyÃ© pour rÃ©gÃ©nÃ©rer :
     - `users.csv`
     - `products.csv`
     - `sessions.csv`
     - `transactions.csv`

2. `load_retailrocket_to_db.py`
   - Charger `events_cleaned.csv` dans PostgreSQL au lieu de `events.csv`

3. Futurs scripts d'analyse
   - Utiliser systÃ©matiquement `events_cleaned.csv` comme source

### Commande de RÃ©gÃ©nÃ©ration (Optionnel)

```bash
# Si vous souhaitez rÃ©gÃ©nÃ©rer les fichiers prÃ©traitÃ©s avec les donnÃ©es nettoyÃ©es
python scripts/preprocess_retailrocket.py --input data/clean/events_cleaned.csv
```

---

## ğŸ“Š MÃ©triques de Performance

### Temps d'ExÃ©cution

- **Chargement** : ~5 secondes (2.7M lignes)
- **DÃ©tection des doublons** : ~2 secondes
- **Suppression** : ~1 seconde
- **Validation** : ~3 secondes
- **Tri** : ~4 secondes
- **Sauvegarde** : ~6 secondes
- **Total** : ~21 secondes âš¡

### Consommation MÃ©moire

- **DonnÃ©es brutes** : ~224 MB en RAM
- **DonnÃ©es nettoyÃ©es** : ~92.53 MB sur disque
- **Pic mÃ©moire** : ~250 MB (pandas overhead)

---

## ğŸ¯ Recommandations pour la Suite

### Court Terme

1. âœ… **Utiliser events_cleaned.csv** pour toutes les analyses futures
2. âœ… **Archiver events.csv** (garder en backup, ne plus utiliser directement)
3. â³ **Mettre Ã  jour load_retailrocket_to_db.py** pour charger les donnÃ©es nettoyÃ©es
4. â³ **Commiter les changements** sur la branche feature/data-preprocessing

### Moyen Terme

1. ğŸ“Š **CrÃ©er un dashboard de qualitÃ© des donnÃ©es**
   - Suivi des doublons au fil du temps
   - Alertes sur anomalies
   - MÃ©triques de fraÃ®cheur des donnÃ©es

2. ğŸ”„ **Automatiser le nettoyage**
   - Pipeline ETL pour nettoyer les nouvelles donnÃ©es
   - Scheduler quotidien/hebdomadaire
   - Validation automatique des rÃ¨gles qualitÃ©

3. ğŸ“ˆ **Tracer l'origine des doublons**
   - Analyser les patterns temporels
   - Identifier les utilisateurs/produits rÃ©currents
   - Corriger la source (tracking, API)

---

## ğŸ› ProblÃ¨mes RÃ©solus

| ProblÃ¨me | Statut | Solution |
|----------|--------|----------|
| 460 doublons dans events.csv | âœ… RÃ©solu | Suppression avec `drop_duplicates()` |
| Ordre non chronologique | âœ… RÃ©solu | Tri par timestamp |
| Validation des transactions | âœ… VÃ©rifiÃ© | Toutes ont un transactionid |
| Types d'Ã©vÃ©nements invalides | âœ… Aucun | Validation passed |
| IDs nÃ©gatifs | âœ… Aucun | Validation passed |

---

## ğŸ“ Notes Techniques

### Algorithme de DÃ©duplication

```python
# Suppression des doublons exacts (toutes colonnes identiques)
df_cleaned = df.drop_duplicates()

# Alternative : Suppression par clÃ©s primaires
# df_cleaned = df.drop_duplicates(subset=['timestamp', 'visitorid', 'itemid'], keep='first')
```

**Choix retenu :** Suppression des doublons exacts (toutes colonnes)

**Raison :** Conserver les Ã©vÃ©nements avec des `transactionid` diffÃ©rents mÃªme si timestamp/user/item sont identiques (cas rares mais lÃ©gitimes).

### Gestion des Valeurs Manquantes

- **transactionid** : 99.19% manquantes (normal, comportement attendu)
- **Autres colonnes** : 0% manquantes âœ…

Pas de remplissage (imputation) nÃ©cessaire.

---

## ğŸ¯ Conclusion

Le nettoyage de `events.csv` est **terminÃ© avec succÃ¨s**. Les donnÃ©es sont maintenant :

âœ… **Sans doublon** (460 lignes supprimÃ©es)  
âœ… **Valides** (timestamps, IDs, types d'Ã©vÃ©nements)  
âœ… **TriÃ©es** chronologiquement  
âœ… **PrÃªtes** pour l'analyse et le chargement en base de donnÃ©es  

**Impact :** Minime (-0.0167%) mais crucial pour la qualitÃ© des analyses.

**QualitÃ© des donnÃ©es :** â­â­â­â­â­ (5/5)

---

## ğŸ“‚ Fichiers du Projet

```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ events.csv (2,756,101 lignes - NE PLUS UTILISER)
â””â”€â”€ clean/
    â”œâ”€â”€ events_cleaned.csv (2,755,641 lignes - Ã€ UTILISER)
    â”œâ”€â”€ CLEANING_REPORT.txt (rapport de nettoyage)
    â”œâ”€â”€ users.csv
    â”œâ”€â”€ products.csv
    â”œâ”€â”€ sessions.csv
    â””â”€â”€ transactions.csv

scripts/
â”œâ”€â”€ clean_events.py (script de nettoyage)
â”œâ”€â”€ inspect_csv.py
â”œâ”€â”€ download_dataset.py
â”œâ”€â”€ preprocess_retailrocket.py
â””â”€â”€ load_retailrocket_to_db.py

docs/
â”œâ”€â”€ ISSUE1_COMPLETED.md
â”œâ”€â”€ ISSUE2_COMPLETED.md
â””â”€â”€ ISSUE3_COMPLETED.md (ce fichier)
```

---

**Date de clÃ´ture :** 2025-12-08  
**Branche :** feature/data-preprocessing  
**Issue :** #3 âœ… CLOSED
